#!/usr/bin/env python3
"""
decisions_data.parquet íŒŒì¼ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
"""

import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from agent.decision_generator import (
    generate_signal_data_with_indicators,
    load_decisions_from_parquet,
    analyze_decision_data,
    inspect_parquet_structure,
    check_existing_decision_data,
    clear_progress_state
)
from managers.binance_dataloader import BinanceDataLoader
from datetime import datetime, timezone, timedelta
import pandas as pd
import time


def load_ethusdt_data_from_api(months_back: int = 3):
    """APIì—ì„œ ETHUSDT ë°ì´í„° ë¡œë“œ (3ë¶„, 15ë¶„, 1ì‹œê°„ë´‰)"""
    print(f"ğŸ“¥ APIì—ì„œ ê°€ê²© ë°ì´í„° ë¡œë“œ ì¤‘... (ìµœê·¼ {months_back}ê°œì›”)")
    
    dataloader = BinanceDataLoader()
    end_time = datetime.now(timezone.utc)
    start_time = end_time - timedelta(days=months_back * 30)
    
    all_dataframes = {}
    
    for interval in ['3m', '15m', '1h']:
        print(f"\n   {interval} ë°ì´í„° ë¡œë“œ ì¤‘...")
        all_dataframes[interval] = []
        
        current_start = start_time
        batch_count = 0
        
        # ë°°ì¹˜ í¬ê¸° ê³„ì‚° (API ì œí•œ: ìµœëŒ€ 1500ê°œ)
        batch_size = 1500
        # ê°„ê²©ë³„ ë¶„ ë‹¨ìœ„
        interval_minutes = {'3m': 3, '15m': 15, '1h': 60}[interval]
        
        while current_start < end_time:
            batch_count += 1
            if batch_count % 10 == 0:
                print(f"      ë°°ì¹˜ {batch_count}... ({current_start.strftime('%Y-%m-%d %H:%M')})")
            
            # ë°°ì¹˜ ì¢…ë£Œ ì‹œê°„ ê³„ì‚°
            batch_end = min(
                current_start + timedelta(minutes=batch_size * interval_minutes),
                end_time
            )
            
            try:
                df = dataloader.fetch_data(
                    interval=interval,
                    symbol="ETHUSDT",
                    limit=batch_size,
                    start_time=current_start,
                    end_time=batch_end
                )
                
                if df is None or df.empty:
                    current_start = batch_end
                    continue
                
                # ì¸ë±ìŠ¤ ì²˜ë¦¬
                if not isinstance(df.index, pd.DatetimeIndex):
                    if 'timestamp' in df.columns:
                        df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)
                        df = df.set_index('timestamp')
                
                all_dataframes[interval].append(df)
                
                # ë‹¤ìŒ ë°°ì¹˜ ì‹œì‘ ì‹œê°„
                if len(df) > 0:
                    current_start = df.index[-1] + timedelta(minutes=interval_minutes)
                else:
                    current_start = batch_end
                
                # API ì œí•œ ë°©ì§€
                time.sleep(0.1)
                
            except Exception as e:
                print(f"      âš ï¸ ë°°ì¹˜ {batch_count} ì˜¤ë¥˜: {e}")
                current_start = batch_end
                continue
        
        # ë°ì´í„° í•©ì¹˜ê¸°
        if all_dataframes[interval]:
            combined_df = pd.concat(all_dataframes[interval], ignore_index=False)
            combined_df = combined_df.sort_index()
            combined_df = combined_df[~combined_df.index.duplicated(keep='first')]
            all_dataframes[interval] = combined_df
            print(f"   âœ… {interval} ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(combined_df)}ê°œ ìº”ë“¤")
        else:
            all_dataframes[interval] = None
    
    return all_dataframes.get('3m'), all_dataframes.get('15m'), all_dataframes.get('1h')


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸ“Š Decision ë°ì´í„° ìƒì„± ì‹œì‘")
    print("=" * 60)
    
    # 1. ê¸°ì¡´ ë°ì´í„° í™•ì¸
    if check_existing_decision_data():
        print("\nâš ï¸  ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤.")
        print("ê¸°ì¡´ íŒŒì¼ì„ ì‚­ì œí•˜ê³  ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...")
        import os
        if os.path.exists("agent/decisions_data.parquet"):
            os.remove("agent/decisions_data.parquet")
            print("âœ… ê¸°ì¡´ íŒŒì¼ ì‚­ì œ ì™„ë£Œ")
        # ì§„í–‰ ìƒíƒœë„ ì‚­ì œ
        clear_progress_state()
    
    # 2. ì‹¤ì œ ETHUSDT ë°ì´í„° ë¡œë“œ (3ë¶„, 15ë¶„, 1ì‹œê°„ë´‰)
    print("\nğŸ“¥ ê°€ê²© ë°ì´í„° ë¡œë“œ ì¤‘...")
    
    # ë¨¼ì € CSV íŒŒì¼ ì‹œë„
    try:
        from agent.decision_generator import load_ethusdt_data
        price_data, price_data_15m, price_data_1h = load_ethusdt_data()
    except:
        price_data, price_data_15m, price_data_1h = None, None, None
    
    # CSVê°€ ì—†ìœ¼ë©´ APIì—ì„œ ë¡œë“œ
    if price_data is None:
        print("âš ï¸ CSV íŒŒì¼ì´ ì—†ì–´ APIì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤...")
        price_data, price_data_15m, price_data_1h = load_ethusdt_data_from_api(months_back=3)
    
    if price_data is None:
        print("âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
        return
    
    print(f"\nâœ… ê°€ê²© ë°ì´í„° ë¡œë“œ ì™„ë£Œ:")
    print(f"   - 3ë¶„ë´‰: {len(price_data)}ê°œ ìº”ë“¤")
    print(f"   - 15ë¶„ë´‰: {len(price_data_15m)}ê°œ ìº”ë“¤")
    print(f"   - 1ì‹œê°„ë´‰: {len(price_data_1h)}ê°œ ìº”ë“¤")
    print(f"   - ê°€ê²© ë²”ìœ„: ${price_data['close'].min():.2f} ~ ${price_data['close'].max():.2f}")
    
    # 3. CSV ë°ì´í„°ë¡œ ì‹¤ì œ ì§€í‘œ ì—…ë°ì´íŠ¸ ë° ì „ëµ ì‹¤í–‰
    print("\nğŸ”„ Decision ë°ì´í„° ìƒì„± ì¤‘...")
    print("   (ì´ ì‘ì—…ì€ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    
    success = generate_signal_data_with_indicators(
        price_data, 
        price_data_15m, 
        price_data_1h, 
        resume_from_progress=False  # ì²˜ìŒë¶€í„° ì‹œì‘
    )
    
    if success:
        print("\n" + "=" * 60)
        print("âœ… Decision ë°ì´í„° ìƒì„± ì™„ë£Œ!")
        print("=" * 60)
        
        # ì €ì¥ëœ ë°ì´í„° í™•ì¸ ë° ë¶„ì„
        df = load_decisions_from_parquet()
        if df is not None:
            print(f"\nğŸ“Š ì €ì¥ëœ ë°ì´í„° ìš”ì•½:")
            print(f"   - ì´ ë ˆì½”ë“œ ìˆ˜: {len(df)}ê°œ")
            print(f"   - ì‹œê°„ ë²”ìœ„: {df['timestamp'].min()} ~ {df['timestamp'].max()}")
            print(f"   - ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}")
            
            # ìƒì„¸ ë¶„ì„
            analyze_decision_data(df)
            
            # Parquet êµ¬ì¡° í™•ì¸
            inspect_parquet_structure()
            
            print(f"\nğŸ¯ íŒŒì¼ ìœ„ì¹˜: agent/decisions_data.parquet")
            print(f"   ì´ ë°ì´í„°ë¥¼ ë©”íƒ€ ë¼ë²¨ë§ í•™ìŠµì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        print("\nâŒ ë°ì´í„° ìƒì„±ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   ì§„í–‰ ìƒíƒœê°€ ì €ì¥ë˜ì–´ ìˆì–´ì„œ ë‹¤ìŒì— ì´ì–´ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()


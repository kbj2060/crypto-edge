#!/usr/bin/env python3
"""
ë©”íƒ€ ë¼ë²¨ë§ ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸

ê³¼ê±° ê±°ë˜ ê²°ì • ë°ì´í„°ì™€ ê°€ê²© ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬
ë©”íƒ€ ë¼ë²¨ë§ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.
"""

import pandas as pd
import sys
from pathlib import Path
from datetime import datetime, timezone, timedelta
from typing import Optional
import time

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from engines.meta_labeling_engine import MetaLabelingEngine
from agent.decision_generator import load_decisions_from_parquet
from managers.binance_dataloader import BinanceDataLoader


def load_price_data_from_csv(csv_path: str = "data/ETHUSDT_3m_20240913_20250913.csv") -> pd.DataFrame:
    """CSV íŒŒì¼ì—ì„œ ê°€ê²© ë°ì´í„° ë¡œë“œ"""
    print(f"ğŸ“Š CSV íŒŒì¼ì—ì„œ ê°€ê²© ë°ì´í„° ë¡œë“œ ì¤‘... ({csv_path})")
    
    csv_file = Path(csv_path)
    if not csv_file.exists():
        raise FileNotFoundError(f"CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")
    
    try:
        df = pd.read_csv(csv_path)
        
        # timestamp ì²˜ë¦¬
        if 'timestamp' in df.columns:
            df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)
            df = df.set_index('timestamp')
        elif not isinstance(df.index, pd.DatetimeIndex):
            raise ValueError("CSV íŒŒì¼ì— timestamp ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤")
        
        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        required_columns = ['open', 'high', 'low', 'close', 'volume']
        available_columns = [col for col in required_columns if col in df.columns]
        df = df[available_columns]
        
        # ì •ë ¬
        df = df.sort_index()
        
        print(f"âœ… CSV ê°€ê²© ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ìº”ë“¤")
        print(f"   ì‹œê°„ ë²”ìœ„: {df.index.min()} ~ {df.index.max()}")
        return df
    except Exception as e:
        raise ValueError(f"CSV íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")


def load_price_data_from_api_batch(
    symbol: str = "ETHUSDT", 
    start_time: Optional[datetime] = None,
    end_time: Optional[datetime] = None,
    batch_size: int = 1500
) -> pd.DataFrame:
    """APIì—ì„œ ê°€ê²© ë°ì´í„°ë¥¼ ë°°ì¹˜ë¡œ ë¡œë“œ (1ë…„ì¹˜ ë°ì´í„°)"""
    print(f"ğŸ“Š APIì—ì„œ ê°€ê²© ë°ì´í„° ë°°ì¹˜ ë¡œë“œ ì¤‘... (ì‹¬ë³¼: {symbol})")
    print(f"   ì‹œê°„ ë²”ìœ„: {start_time} ~ {end_time}")
    
    dataloader = BinanceDataLoader()
    all_dataframes = []
    
    current_start = start_time
    batch_count = 0
    
    while current_start < end_time:
        batch_count += 1
        print(f"   ë°°ì¹˜ {batch_count} ë¡œë“œ ì¤‘... ({current_start.strftime('%Y-%m-%d %H:%M')})")
        
        try:
            # ê° ë°°ì¹˜ì˜ end_time ê³„ì‚° (batch_sizeë§Œí¼ì˜ ìº”ë“¤)
            # 3ë¶„ë´‰ì´ë¯€ë¡œ batch_size * 3ë¶„ = batch_size * 3ë¶„
            batch_end = min(
                current_start + timedelta(minutes=batch_size * 3),
                end_time
            )
            
            df = dataloader.fetch_data(
                interval="3m",
                symbol=symbol,
                limit=batch_size,
                start_time=current_start,
                end_time=batch_end
            )
            
            if df is None or df.empty:
                print(f"   âš ï¸ ë°°ì¹˜ {batch_count} ë°ì´í„° ì—†ìŒ, ë‹¤ìŒ ë°°ì¹˜ë¡œ...")
                current_start = batch_end
                continue
            
            # ì¸ë±ìŠ¤ ì²˜ë¦¬
            if not isinstance(df.index, pd.DatetimeIndex):
                if 'timestamp' in df.columns:
                    df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)
                    df = df.set_index('timestamp')
            
            all_dataframes.append(df)
            
            # ë‹¤ìŒ ë°°ì¹˜ ì‹œì‘ ì‹œê°„ (ë§ˆì§€ë§‰ ìº”ë“¤ ì‹œê°„ + 3ë¶„)
            if len(df) > 0:
                current_start = df.index[-1] + timedelta(minutes=3)
            else:
                current_start = batch_end
            
            # API ì œí•œì„ í”¼í•˜ê¸° ìœ„í•œ ëŒ€ê¸°
            time.sleep(0.1)
            
        except Exception as e:
            print(f"   âš ï¸ ë°°ì¹˜ {batch_count} ë¡œë“œ ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨í•´ë„ ë‹¤ìŒ ë°°ì¹˜ ì‹œë„
            if current_start < end_time:
                current_start = current_start + timedelta(days=1)
            else:
                break
    
    if not all_dataframes:
        raise ValueError(f"APIì—ì„œ ê°€ê²© ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {symbol}")
    
    # ëª¨ë“  ë°ì´í„°í”„ë ˆì„ í•©ì¹˜ê¸°
    combined_df = pd.concat(all_dataframes)
    combined_df = combined_df.sort_index()
    
    # ì¤‘ë³µ ì œê±°
    combined_df = combined_df[~combined_df.index.duplicated(keep='first')]
    
    print(f"âœ… API ê°€ê²© ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(combined_df)}ê°œ ìº”ë“¤ (ì´ {batch_count}ê°œ ë°°ì¹˜)")
    return combined_df


def load_price_data(
    decisions_df: Optional[pd.DataFrame] = None,
    symbol: str = "ETHUSDT",
    years_back: int = 1
) -> pd.DataFrame:
    """ê°€ê²© ë°ì´í„° ë¡œë“œ (CSV ìš°ì„ , API í´ë°±)"""
    # 1. CSV íŒŒì¼ ì‹œë„
    csv_paths = [
        "data/ETHUSDT_3m_20240913_20250913.csv",
        "data/ETHUSDT_3m_20230913_20240913.csv"
    ]
    
    for csv_path in csv_paths:
        csv_file = Path(csv_path)
        if csv_file.exists():
            try:
                df = load_price_data_from_csv(csv_path)
                
                # ê²°ì • ë°ì´í„°ì˜ ì‹œê°„ ë²”ìœ„ì— ë§ì¶° í•„í„°ë§
                if decisions_df is not None and not decisions_df.empty:
                    if 'timestamp' in decisions_df.columns:
                        decisions_df = decisions_df.set_index('timestamp')
                    
                    min_time = decisions_df.index.min()
                    max_time = decisions_df.index.max()
                    
                    # ì‹œê°„ ë²”ìœ„ í™•ì¥ (ì•ë’¤ë¡œ ì—¬ìœ  ì‹œê°„)
                    time_buffer = pd.Timedelta(hours=24)
                    min_time = min_time - time_buffer
                    max_time = max_time + time_buffer
                    
                    df = df[(df.index >= min_time) & (df.index <= max_time)]
                    print(f"   ê²°ì • ë°ì´í„° ì‹œê°„ ë²”ìœ„ì— ë§ì¶° í•„í„°ë§: {len(df)}ê°œ ìº”ë“¤")
                elif years_back > 0:
                    # ë…„ìˆ˜ë¡œ í•„í„°ë§
                    now = datetime.now(timezone.utc)
                    cutoff_time = now - timedelta(days=years_back * 365)
                    df = df[df.index >= cutoff_time]
                    print(f"   {years_back}ë…„ì¹˜ ë°ì´í„° í•„í„°ë§: {len(df)}ê°œ ìº”ë“¤")
                
                return df
            except Exception as e:
                print(f"âš ï¸ CSV ë¡œë“œ ì‹¤íŒ¨ ({csv_path}): {e}")
                continue
    
    # 2. API ì‹œë„
    print("âš ï¸ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ APIì—ì„œ ë¡œë“œ ì‹œë„...")
    
    # ì‹œê°„ ë²”ìœ„ ê²°ì •
    now = datetime.now(timezone.utc)
    end_time = now
    start_time = now - timedelta(days=years_back * 365)
    
    if decisions_df is not None and not decisions_df.empty:
        if 'timestamp' in decisions_df.columns:
            decisions_df = decisions_df.set_index('timestamp')
        
        # ê²°ì • ë°ì´í„°ì˜ ì‹œê°„ ë²”ìœ„ì™€ êµì§‘í•©
        decision_min = decisions_df.index.min().to_pydatetime()
        decision_max = decisions_df.index.max().to_pydatetime()
        
        start_time = max(start_time, decision_min)
        end_time = min(end_time, decision_max)
    
    print(f"   APIì—ì„œ {years_back}ë…„ì¹˜ ë°ì´í„° ìš”ì²­: {start_time} ~ {end_time}")
    return load_price_data_from_api_batch(symbol, start_time, end_time)


def load_decision_data(
    filename: str = "agent/decisions_data.parquet",
    years_back: int = 1
) -> pd.DataFrame:
    """ê²°ì • ë°ì´í„° ë¡œë“œ (ì§€ì •ëœ ë…„ìˆ˜ë§Œí¼)"""
    print(f"ğŸ“Š ê²°ì • ë°ì´í„° ë¡œë“œ ì¤‘... ({filename})")
    
    df = load_decisions_from_parquet(filename)
    
    if df is None or df.empty:
        raise ValueError(f"ê²°ì • ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filename}")
    
    # timestamp ì²˜ë¦¬ (ë¬¸ìì—´ë¡œ ì €ì¥ëœ ê²½ìš° ì²˜ë¦¬)
    if 'timestamp' in df.columns:
        # ë¬¸ìì—´ì¸ ê²½ìš° íŒŒì‹±
        if df['timestamp'].dtype == 'object':
            # "YYYY-MM-DD HH:MM:SS UTC" í˜•ì‹ ì²˜ë¦¬
            df['timestamp'] = df['timestamp'].str.replace(' UTC', '', regex=False)
            df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True, errors='coerce')
        else:
            df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True, errors='coerce')
        
        # ìœ íš¨í•˜ì§€ ì•Šì€ timestamp ì œê±°
        df = df.dropna(subset=['timestamp'])
        df = df.set_index('timestamp')
    elif not isinstance(df.index, pd.DatetimeIndex):
        raise ValueError("ê²°ì • ë°ì´í„°ì— timestampê°€ ì—†ìŠµë‹ˆë‹¤")
    
    # ì‹œê°„ ë²”ìœ„ í•„í„°ë§ (ì§€ê¸ˆìœ¼ë¡œë¶€í„° Në…„ ì „ê¹Œì§€)
    if years_back > 0:
        now = datetime.now(timezone.utc)
        cutoff_time = now - timedelta(days=years_back * 365)
        
        original_count = len(df)
        # í˜„ì¬ ì‹œê°„ ì´ì „ì˜ ë°ì´í„°ë§Œ ì‚¬ìš© (ë¯¸ë˜ ë°ì´í„° ì œì™¸)
        df = df[(df.index >= cutoff_time) & (df.index <= now)]
        
        print(f"   ì „ì²´ ë°ì´í„°: {original_count}ê°œ")
        print(f"   í•„í„°ë§ í›„: {len(df)}ê°œ (ì§€ê¸ˆìœ¼ë¡œë¶€í„° {years_back}ë…„, {cutoff_time.strftime('%Y-%m-%d')} ~ {now.strftime('%Y-%m-%d')})")
    
    print(f"âœ… ê²°ì • ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ë ˆì½”ë“œ")
    if len(df) > 0:
        print(f"   ì‹œê°„ ë²”ìœ„: {df.index.min()} ~ {df.index.max()}")
    
    return df.reset_index()


def prepare_data(decisions_df: pd.DataFrame, price_df: pd.DataFrame) -> tuple:
    """ë°ì´í„° ì¤€ë¹„ ë° ì •ë ¬"""
    print("ğŸ”§ ë°ì´í„° ì¤€ë¹„ ì¤‘...")
    
    # timestamp ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
    if 'timestamp' in decisions_df.columns:
        decisions_df = decisions_df.set_index('timestamp')
    
    decisions_df = decisions_df.sort_index()
    price_df = price_df.sort_index()
    
    # ì‹œê°„ ë²”ìœ„ ë§ì¶”ê¸°
    min_time = max(decisions_df.index.min(), price_df.index.min())
    max_time = min(decisions_df.index.max(), price_df.index.max())
    
    decisions_df = decisions_df[
        (decisions_df.index >= min_time) & 
        (decisions_df.index <= max_time)
    ]
    price_df = price_df[
        (price_df.index >= min_time) & 
        (price_df.index <= max_time)
    ]
    
    print(f"âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ:")
    print(f"   ê²°ì • ë°ì´í„°: {len(decisions_df)}ê°œ")
    print(f"   ê°€ê²© ë°ì´í„°: {len(price_df)}ê°œ")
    print(f"   ì‹œê°„ ë²”ìœ„: {min_time} ~ {max_time}")
    
    return decisions_df.reset_index(), price_df


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 60)
    print("ë©”íƒ€ ë¼ë²¨ë§ ëª¨ë¸ í•™ìŠµ ì‹œì‘ (1ë…„ì¹˜ ë°ì´í„°)")
    print("=" * 60)
    
    years_back = 1  # ì§€ê¸ˆìœ¼ë¡œë¶€í„° 1ë…„
    
    # 1. ë°ì´í„° ë¡œë“œ
    try:
        decisions_df = load_decision_data("agent/decisions_data.parquet", years_back=years_back)
        price_df = load_price_data(decisions_df, "ETHUSDT", years_back=years_back)
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # 2. ë°ì´í„° ì¤€ë¹„
    try:
        decisions_df, price_df = prepare_data(decisions_df, price_df)
    except Exception as e:
        print(f"âŒ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {e}")
        return
    
    # 3. ë©”íƒ€ ë¼ë²¨ë§ ì—”ì§„ ì´ˆê¸°í™” (ì„±ëŠ¥ ê°œì„  ë²„ì „)
    print("\nğŸ¤– ë©”íƒ€ ë¼ë²¨ë§ ì—”ì§„ ì´ˆê¸°í™”...")
    engine = MetaLabelingEngine(
        model_type="random_forest",  # ë˜ëŠ” "gradient_boosting" ì‹œë„ ê°€ëŠ¥
        min_samples_for_training=100,
        confidence_threshold=0.7  # 0.6 â†’ 0.7 (ë” ë³´ìˆ˜ì )
    )
    
    # 4. ëª¨ë¸ í•™ìŠµ
    print("\nğŸ“ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    try:
        result = engine.train(
            decisions_df=decisions_df,
            price_data=price_df,
            test_size=0.2,
            retrain=True,
            min_profit_threshold=0.005,  # ìµœì†Œ 0.5% ìˆ˜ìµ
            use_profit_based=True  # ì‹¤ì œ ìˆ˜ìµë¥  ê¸°ë°˜ ë¼ë²¨ë§
        )
        
        if result["success"]:
            print("\n" + "=" * 60)
            print("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
            print("=" * 60)
            print(f"ì •í™•ë„: {result['accuracy']:.3f}")
            print(f"ROC-AUC: {result['roc_auc']:.3f}")
            print(f"í•™ìŠµ ìƒ˜í”Œ: {result['train_samples']}ê°œ")
            print(f"í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {result['test_samples']}ê°œ")
            
            if result.get('feature_importance'):
                print("\níŠ¹ì„± ì¤‘ìš”ë„ (ìƒìœ„ 5ê°œ):")
                sorted_features = sorted(
                    result['feature_importance'].items(),
                    key=lambda x: x[1],
                    reverse=True
                )[:5]
                for feature, importance in sorted_features:
                    print(f"  {feature}: {importance:.3f}")
        else:
            print(f"\nâŒ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {result.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
    
    except Exception as e:
        print(f"\nâŒ ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()



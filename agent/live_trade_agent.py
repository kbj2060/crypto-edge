# ì‹¤ì‹œê°„ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ - í›ˆë ¨ëœ ì—ì´ì „íŠ¸ë¡œ ì‹¤ì œ ê±°ë˜ ê²°ì •

import numpy as np
import pandas as pd
import torch
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
import json

from agent.ai import ImprovedCryptoRLAgent

class LiveTradingAgent:
    """ì‹¤ì‹œê°„ ê±°ë˜ë¥¼ ìœ„í•œ ì—ì´ì „íŠ¸ ë˜í¼"""
    
    def __init__(self, model_path: str, initial_balance: float = 10000.0):
        """
        Args:
            model_path: í›ˆë ¨ëœ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
            initial_balance: ì‹œì‘ ì”ê³ 
        """
        self.model_path = model_path
        self.initial_balance = initial_balance
        
        # í¬íŠ¸í´ë¦¬ì˜¤ ìƒíƒœ
        self.current_balance = initial_balance
        self.current_position = 0.0
        self.current_leverage = 1.0
        self.entry_price = 0.0
        self.holding_time = 0
        self.in_position = False
        
        # ê±°ë˜ í†µê³„
        self.total_trades = 0
        self.winning_trades = 0
        self.max_drawdown = 0.0
        self.peak_balance = initial_balance
        
        # ê°€ê²© íˆìŠ¤í† ë¦¬ (ìƒíƒœ ê³„ì‚°ìš©)
        self.price_history = []
        
        # í›ˆë ¨ëœ ì—ì´ì „íŠ¸ ë¡œë“œ
        self.agent = self._load_trained_agent()
        
        print(f"âœ… ì‹¤ì‹œê°„ íŠ¸ë ˆì´ë”© ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   ëª¨ë¸: {model_path}")
        print(f"   ì´ˆê¸° ì”ê³ : ${initial_balance:,.2f}")
    
    def _load_trained_agent(self):
        """í›ˆë ¨ëœ ì—ì´ì „íŠ¸ ë¡œë“œ"""
        try:
            # ì—ì´ì „íŠ¸ ìƒì„± (ìƒíƒœ í¬ê¸°ëŠ” 60ìœ¼ë¡œ ê³ ì •)
            agent = ImprovedCryptoRLAgent(state_size=60)
            
            # ëª¨ë¸ ë¡œë“œ
            if agent.safe_load_model(self.model_path):
                agent.epsilon = 0.0  # ì‹¤ê±°ë˜ì—ì„œëŠ” íƒí—˜ ë¹„í™œì„±í™”
                print(f"âœ… í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
                return agent
            else:
                raise Exception("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
                
        except Exception as e:
            print(f"âŒ ì—ì´ì „íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def update_price(self, ohlcv_data: Dict[str, float]):
        """ìƒˆë¡œìš´ ê°€ê²© ë°ì´í„° ì—…ë°ì´íŠ¸"""
        self.price_history.append(ohlcv_data)
        
        # ìµœëŒ€ 100ê°œê¹Œì§€ë§Œ ìœ ì§€ (ë©”ëª¨ë¦¬ ì ˆì•½)
        if len(self.price_history) > 100:
            self.price_history.pop(0)
    
    def make_trading_decision(self, current_signals: Dict[str, Any], 
                            current_price: float) -> Dict[str, Any]:
        """
        ì‹¤ì‹œê°„ ê±°ë˜ ê²°ì • ìƒì„±
        
        Args:
            current_signals: ë‹¹ì‹ ì˜ ì „ëµì—ì„œ ìƒì„±ëœ ìµœì‹  ì‹ í˜¸
            current_price: í˜„ì¬ ê°€ê²©
            
        Returns:
            ê±°ë˜ ê²°ì • ë”•ì…”ë„ˆë¦¬
        """
        
        if self.agent is None:
            return self._get_default_decision("ì—ì´ì „íŠ¸ ë¡œë“œ ì‹¤íŒ¨")
        
        if len(self.price_history) < 20:
            return self._get_default_decision("ê°€ê²© íˆìŠ¤í† ë¦¬ ë¶€ì¡±")
        
        try:
            # 1. í˜„ì¬ ìƒíƒœ êµ¬ì„±
            current_state = self._build_current_state(current_signals, current_price)
            
            # 2. AI ì—ì´ì „íŠ¸ì˜ ì•¡ì…˜ ì˜ˆì¸¡
            ai_action = self.agent.act(current_state)
            
            # 3. ì•¡ì…˜ì„ ê±°ë˜ ê²°ì •ìœ¼ë¡œ ë³€í™˜
            trading_decision = self._convert_action_to_decision(ai_action, current_price, current_signals)
            
            # 4. ë¦¬ìŠ¤í¬ ì²´í¬ ë° ìµœì¢… ê²°ì •
            final_decision = self._apply_risk_controls(trading_decision, current_price)
            
            return final_decision
            
        except Exception as e:
            print(f"âŒ ê±°ë˜ ê²°ì • ìƒì„± ì˜¤ë¥˜: {e}")
            return self._get_default_decision(f"ì˜¤ë¥˜: {str(e)}")
    
    def _build_current_state(self, signals: Dict[str, Any], current_price: float) -> np.ndarray:
        """í˜„ì¬ ìƒíƒœ ë²¡í„° êµ¬ì„± (í›ˆë ¨ ì‹œì™€ ë™ì¼í•œ í˜•íƒœë¡œ)"""
        
        # 1. ê°€ê²© íŠ¹ì„± (20ê°œ)
        price_features = self._extract_price_features()
        
        # 2. ì‹ í˜¸ íŠ¹ì„± (30ê°œ)
        signal_features = self._extract_signal_features(signals)
        
        # 3. í¬íŠ¸í´ë¦¬ì˜¤ íŠ¹ì„± (10ê°œ)
        portfolio_features = self._extract_portfolio_features()
        
        # ëª¨ë“  íŠ¹ì„± ê²°í•©
        state = np.concatenate([price_features, signal_features, portfolio_features])
        
        return state.astype(np.float32)
    
    def _extract_price_features(self) -> np.ndarray:
        """ê°€ê²© íˆìŠ¤í† ë¦¬ì—ì„œ íŠ¹ì„± ì¶”ì¶œ (í›ˆë ¨ ì‹œì™€ ë™ì¼)"""
        if len(self.price_history) < 20:
            return np.zeros(20, dtype=np.float32)
        
        # DataFrameìœ¼ë¡œ ë³€í™˜
        df = pd.DataFrame(self.price_history[-20:])
        
        features = []
        
        close = df['close']
        high = df['high']
        low = df['low']
        volume = df['volume']
        
        # ìˆ˜ìµë¥  íŠ¹ì„±
        returns = close.pct_change().fillna(0)
        features.extend([
            returns.mean(),
            returns.std(),
            returns.iloc[-1],
            returns.tail(5).mean()
        ])
        
        # RSI
        if len(close) >= 14:
            delta = close.diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14, min_periods=1).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14, min_periods=1).mean()
            rs = gain / (loss + 1e-8)
            rsi = 100 - (100 / (1 + rs))
            features.append(rsi.iloc[-1] / 100.0)
        else:
            features.append(0.5)
        
        # ë³¼ë¦°ì € ë°´ë“œ ìœ„ì¹˜
        if len(close) >= 20:
            sma = close.rolling(window=20, min_periods=1).mean()
            std = close.rolling(window=20, min_periods=1).std()
            bb_upper = sma + (std * 2)
            bb_lower = sma - (std * 2)
            bb_width = bb_upper.iloc[-1] - bb_lower.iloc[-1]
            if bb_width > 0:
                bb_position = (close.iloc[-1] - bb_lower.iloc[-1]) / bb_width
            else:
                bb_position = 0.5
            features.append(bb_position)
        else:
            features.append(0.5)
        
        # ì´ë™í‰ê·  ë¹„ìœ¨
        for window in [5, 10, 20]:
            if len(close) >= window:
                ma = close.rolling(window=window, min_periods=1).mean()
                ma_ratio = (close.iloc[-1] / ma.iloc[-1] - 1) if ma.iloc[-1] > 0 else 0.0
                features.append(ma_ratio)
            else:
                features.append(0.0)
        
        # ë‚˜ë¨¸ì§€ íŠ¹ì„±ë“¤ë¡œ 20ê°œ ë§ì¶”ê¸°
        while len(features) < 20:
            features.append(0.0)
        
        return np.array(features[:20], dtype=np.float32)
    
    def _extract_signal_features(self, signals: Dict[str, Any]) -> np.ndarray:
        """ì‹ í˜¸ì—ì„œ íŠ¹ì„± ì¶”ì¶œ (í›ˆë ¨ ì‹œì™€ ë™ì¼)"""
        features = []
        
        # ê° ì‹œê°„ëŒ€ë³„ ì‹ í˜¸ íŠ¹ì„±
        for category in ['SHORT_TERM', 'MEDIUM_TERM', 'LONG_TERM']:
            if 'decisions' in signals and category in signals['decisions']:
                decision = signals['decisions'][category]
                
                action = decision.get('action', 'HOLD')
                action_strength = 1.0 if action == 'LONG' else (-1.0 if action == 'SHORT' else 0.0)
                
                features.extend([
                    action_strength,
                    float(decision.get('net_score', 0.0)),
                    min(float(decision.get('leverage', 1)) / 10.0, 2.0),
                    min(float(decision.get('max_holding_minutes', 60)) / 1440.0, 1.0),
                ])
                
                meta = decision.get('meta', {}).get('synergy_meta', {})
                confidence = meta.get('confidence', 'LOW')
                confidence_score = 1.0 if confidence == 'HIGH' else (0.5 if confidence == 'MEDIUM' else 0.0)
                
                features.extend([
                    confidence_score,
                    float(meta.get('buy_score', 0.0)),
                    float(meta.get('sell_score', 0.0)),
                    len(meta.get('conflicts_detected', [])) / 5.0
                ])
            else:
                features.extend([0.0] * 8)
        
        # ê°ˆë“± ë° ë©”íƒ€ ì •ë³´
        if 'conflicts' in signals:
            conflicts = signals['conflicts']
            features.extend([
                1.0 if conflicts.get('has_conflicts', False) else 0.0,
                len(conflicts.get('long_categories', [])) / 3.0,
                len(conflicts.get('short_categories', [])) / 3.0,
                float(signals.get('meta', {}).get('active_positions', 0)) / 3.0,
                0.0,
                0.0
            ])
        else:
            features.extend([0.0] * 6)
        
        return np.array(features[:30], dtype=np.float32)
    
    def _extract_portfolio_features(self) -> np.ndarray:
        """í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ ìƒíƒœ íŠ¹ì„±"""
        features = [
            self.current_position,
            self.current_leverage / 20.0,
            (self.current_balance - self.initial_balance) / self.initial_balance,
            0.0,  # unrealized_pnl (ì‹¤ì‹œê°„ì—ì„œëŠ” ê³„ì‚° ë³µì¡)
            min(self.total_trades / 100.0, 1.0),
            self.winning_trades / max(self.total_trades, 1),
            self.max_drawdown,
            0.0,  # consecutive_losses (ë‹¨ìˆœí™”)
            min(self.holding_time / 1440.0, 1.0),
            1.0 if self.in_position else 0.0
        ]
        return np.array(features, dtype=np.float32)
    
    def _convert_action_to_decision(self, ai_action: np.ndarray, current_price: float, 
                                  signals: Dict[str, Any]) -> Dict[str, Any]:
        """AI ì•¡ì…˜ì„ ì‹¤ì œ ê±°ë˜ ê²°ì •ìœ¼ë¡œ ë³€í™˜"""
        
        position_change = ai_action[0]
        leverage = ai_action[1] 
        holding_minutes = ai_action[2]
        
        # ê±°ë˜ ê²°ì • ìƒì„±
        decision = {
            'timestamp': datetime.now(),
            'current_price': current_price,
            'ai_confidence': self._calculate_confidence(ai_action),
            'position_change': position_change,
            'target_leverage': leverage,
            'target_holding_minutes': holding_minutes,
            'action': 'HOLD',  # ê¸°ë³¸ê°’
            'reason': '',
            'quantity': 0.0,
            'stop_loss': None,
            'take_profit': None
        }
        
        # ì•¡ì…˜ í•´ì„
        if abs(position_change) > 0.1:  # ì˜ë¯¸ìˆëŠ” í¬ì§€ì…˜ ë³€ê²½
            if position_change > 0.1:
                decision['action'] = 'BUY'
                decision['reason'] = f"AI ì¶”ì²œ: Long í¬ì§€ì…˜ {position_change:.2f}"
            elif position_change < -0.1:
                decision['action'] = 'SELL'  
                decision['reason'] = f"AI ì¶”ì²œ: Short í¬ì§€ì…˜ {abs(position_change):.2f}"
            
            # í¬ì§€ì…˜ í¬ê¸° ê³„ì‚° (Kelly Criterion ê¸°ë°˜)
            decision['quantity'] = self._calculate_position_size(position_change, leverage)
            
            # ìŠ¤íƒ‘ë¡œìŠ¤/ìµì ˆ ì„¤ì •
            decision['stop_loss'], decision['take_profit'] = self._calculate_stops(
                current_price, decision['action'], holding_minutes
            )
        
        return decision
    
    def _calculate_confidence(self, ai_action: np.ndarray) -> float:
        """AI ê²°ì •ì˜ ì‹ ë¢°ë„ ê³„ì‚°"""
        # í¬ì§€ì…˜ ë³€ê²½ëŸ‰ì´ í´ìˆ˜ë¡ ë†’ì€ ì‹ ë¢°ë„
        position_confidence = min(abs(ai_action[0]) / 2.0, 1.0)
        
        # ë ˆë²„ë¦¬ì§€ê°€ ë†’ì„ìˆ˜ë¡ ë†’ì€ ì‹ ë¢°ë„ (ë‹¨, ê³¼ë„í•˜ë©´ ê°ì )
        leverage_confidence = min(ai_action[1] / 5.0, 1.0) * (0.8 if ai_action[1] > 10 else 1.0)
        
        # ì¢…í•© ì‹ ë¢°ë„
        overall_confidence = (position_confidence + leverage_confidence) / 2
        
        return min(overall_confidence, 1.0)
    
    def _calculate_position_size(self, position_change: float, leverage: float) -> float:
        """í¬ì§€ì…˜ í¬ê¸° ê³„ì‚° (ë¦¬ìŠ¤í¬ ê¸°ë°˜)"""
        # ê¸°ë³¸ ë¦¬ìŠ¤í¬: ì”ê³ ì˜ 2%
        base_risk = self.current_balance * 0.02
        
        # í¬ì§€ì…˜ ë³€ê²½ëŸ‰ì— ë”°ë¥¸ ì¡°ì •
        position_multiplier = min(abs(position_change), 1.0)
        
        # ë ˆë²„ë¦¬ì§€ ì œí•œ (ìµœëŒ€ 5ë°°)
        safe_leverage = min(leverage, 5.0)
        
        # ìµœì¢… í¬ì§€ì…˜ í¬ê¸° (USD)
        position_usd = base_risk * position_multiplier * safe_leverage
        
        # ìµœëŒ€ ì”ê³ ì˜ 20%ë¡œ ì œí•œ
        max_position = self.current_balance * 0.2
        
        return min(position_usd, max_position)
    
    def _calculate_stops(self, current_price: float, action: str, 
                        holding_minutes: float) -> Tuple[Optional[float], Optional[float]]:
        """ìŠ¤íƒ‘ë¡œìŠ¤ì™€ ìµì ˆê°€ ê³„ì‚°"""
        
        # ATR ê¸°ë°˜ (ë‹¨ìˆœí™”: ê°€ê²©ì˜ 2%)
        atr_estimate = current_price * 0.02
        
        if action == 'BUY':
            stop_loss = current_price - (atr_estimate * 1.5)  # 1.5 ATR
            take_profit = current_price + (atr_estimate * 1.0)  # 1.0 ATR (ìŠ¹ë¥  ìš°ì„ )
        elif action == 'SELL':
            stop_loss = current_price + (atr_estimate * 1.5)
            take_profit = current_price - (atr_estimate * 1.0)
        else:
            return None, None
        
        # í™€ë”© ì‹œê°„ì´ ì§§ìœ¼ë©´ ë” íƒ€ì´íŠ¸í•œ ìŠ¤íƒ‘
        if holding_minutes < 120:  # 2ì‹œê°„ ë¯¸ë§Œ
            stop_multiplier = 0.7
            profit_multiplier = 0.8
        else:
            stop_multiplier = 1.0
            profit_multiplier = 1.0
        
        if action == 'BUY':
            stop_loss = current_price - (atr_estimate * 1.5 * stop_multiplier)
            take_profit = current_price + (atr_estimate * 1.0 * profit_multiplier)
        elif action == 'SELL':
            stop_loss = current_price + (atr_estimate * 1.5 * stop_multiplier)
            take_profit = current_price - (atr_estimate * 1.0 * profit_multiplier)
        
        return stop_loss, take_profit
    
    def _apply_risk_controls(self, decision: Dict[str, Any], current_price: float) -> Dict[str, Any]:
        """ìµœì¢… ë¦¬ìŠ¤í¬ ì²´í¬ ë° ê±°ë˜ ê²°ì • ì¡°ì •"""
        
        # 1. ìµœëŒ€ ë“œë¡œìš°ë‹¤ìš´ ì²´í¬
        current_drawdown = (self.peak_balance - self.current_balance) / self.peak_balance
        if current_drawdown > 0.15:  # 15% ì´ìƒ ì†ì‹¤ì‹œ
            decision['action'] = 'HOLD'
            decision['reason'] = f"ë¦¬ìŠ¤í¬ ê´€ë¦¬: ìµœëŒ€ ì†ì‹¤ í•œë„ ë„ë‹¬ ({current_drawdown:.1%})"
            decision['quantity'] = 0.0
            return decision
        
        # 2. í¬ì§€ì…˜ í¬ê¸° ì¬ê²€ì¦
        if decision['quantity'] > self.current_balance * 0.3:  # 30% ì´ˆê³¼ ê¸ˆì§€
            decision['quantity'] = self.current_balance * 0.3
            decision['reason'] += " (í¬ì§€ì…˜ í¬ê¸° ì¡°ì •)"
        
        # 3. ì—°ì† ì†ì‹¤ í›„ ë³´ìˆ˜ì  ì§„ì…
        if hasattr(self, 'recent_losses') and self.recent_losses > 3:
            decision['quantity'] *= 0.5  # í¬ì§€ì…˜ í¬ê¸° ë°˜ê°
            decision['reason'] += " (ì—°ì† ì†ì‹¤ í›„ ë³´ìˆ˜ì  ì§„ì…)"
        
        # 4. ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë©´ ê±°ë˜ ê¸ˆì§€
        if decision['ai_confidence'] < 0.3:
            decision['action'] = 'HOLD'
            decision['reason'] = f"ì‹ ë¢°ë„ ë¶€ì¡± ({decision['ai_confidence']:.2f})"
            decision['quantity'] = 0.0
        
        return decision
    
    def _get_default_decision(self, reason: str) -> Dict[str, Any]:
        """ê¸°ë³¸ ê²°ì • (ê±°ë˜ ì•ˆí•¨)"""
        return {
            'timestamp': datetime.now(),
            'action': 'HOLD',
            'reason': reason,
            'quantity': 0.0,
            'ai_confidence': 0.0,
            'stop_loss': None,
            'take_profit': None
        }
    
    def execute_decision(self, decision: Dict[str, Any]) -> bool:
        """ê±°ë˜ ê²°ì • ì‹¤í–‰ (ì‹¤ì œ ê±°ë˜ì†Œ ì—°ë™ì€ ì—¬ê¸°ì„œ)"""
        
        if decision['action'] == 'HOLD':
            print(f"â¸ï¸  ê±°ë˜ ì—†ìŒ: {decision['reason']}")
            return True
        
        print(f"ğŸ“Š AI ê±°ë˜ ê²°ì •:")
        print(f"   ì•¡ì…˜: {decision['action']}")
        print(f"   ìˆ˜ëŸ‰: ${decision['quantity']:.2f}")
        print(f"   ì‹ ë¢°ë„: {decision['ai_confidence']:.2f}")
        print(f"   ìŠ¤íƒ‘ë¡œìŠ¤: ${decision['stop_loss']:.2f}" if decision['stop_loss'] else "   ìŠ¤íƒ‘ë¡œìŠ¤: ì—†ìŒ")
        print(f"   ìµì ˆê°€: ${decision['take_profit']:.2f}" if decision['take_profit'] else "   ìµì ˆê°€: ì—†ìŒ")
        print(f"   ì´ìœ : {decision['reason']}")
        
        # ì‹¤ì œ ê±°ë˜ì†Œ API í˜¸ì¶œì€ ì—¬ê¸°ì— êµ¬í˜„
        # exchange_api.place_order(...)
        
        return True
    
    def update_trade_result(self, trade_pnl: float):
        """ê±°ë˜ ê²°ê³¼ ì—…ë°ì´íŠ¸"""
        self.total_trades += 1
        
        if trade_pnl > 0:
            self.winning_trades += 1
            print(f"âœ… ìˆ˜ìµ ê±°ë˜: +${trade_pnl:.2f}")
        else:
            print(f"âŒ ì†ì‹¤ ê±°ë˜: ${trade_pnl:.2f}")
        
        # ì”ê³  ì—…ë°ì´íŠ¸
        self.current_balance += trade_pnl
        
        # ìµœëŒ€ ë‚™í­ ì—…ë°ì´íŠ¸
        if self.current_balance > self.peak_balance:
            self.peak_balance = self.current_balance
        else:
            drawdown = (self.peak_balance - self.current_balance) / self.peak_balance
            self.max_drawdown = max(self.max_drawdown, drawdown)
        
        # í†µê³„ ì¶œë ¥
        win_rate = self.winning_trades / self.total_trades
        total_return = (self.current_balance - self.initial_balance) / self.initial_balance
        
        print(f"ğŸ“ˆ í˜„ì¬ í†µê³„: ìŠ¹ë¥  {win_rate:.1%}, ìˆ˜ìµë¥  {total_return:.1%}, ì”ê³  ${self.current_balance:.2f}")

# =================================================================
# ì‚¬ìš© ì˜ˆì‹œ
# =================================================================

def example_live_trading():
    """ì‹¤ì‹œê°„ íŠ¸ë ˆì´ë”© ì‚¬ìš© ì˜ˆì‹œ"""
    
    # 1. í›ˆë ¨ëœ ì—ì´ì „íŠ¸ ë¡œë“œ
    live_agent = LiveTradingAgent(
        model_path='agent/final_optimized_model.pth',  # í›ˆë ¨ëœ ëª¨ë¸ ê²½ë¡œ
        initial_balance=10000.0
    )
    
    # 2. ì‹¤ì‹œê°„ ê±°ë˜ ë£¨í”„ ì‹œë®¬ë ˆì´ì…˜
    print("\nğŸš€ ì‹¤ì‹œê°„ íŠ¸ë ˆì´ë”© ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘")
    
    # ê°€ìƒì˜ ì‹¤ì‹œê°„ ë°ì´í„°
    for i in range(10):  # 10ë²ˆì˜ ê±°ë˜ ê¸°íšŒ
        
        # í˜„ì¬ ê°€ê²© ë°ì´í„° (ì‹¤ì œë¡œëŠ” ê±°ë˜ì†Œ APIì—ì„œ ê°€ì ¸ì˜´)
        current_ohlcv = {
            'open': 3000 + i,
            'high': 3010 + i,
            'low': 2995 + i,
            'close': 3005 + i,
            'volume': 1000000
        }
        
        # ë‹¹ì‹ ì˜ ì „ëµ ì‹ í˜¸ (ì‹¤ì œë¡œëŠ” strategy_executorì—ì„œ ê°€ì ¸ì˜´)
        current_signals = {
            'decisions': {
                'SHORT_TERM': {
                    'action': 'LONG' if i % 3 == 0 else ('SHORT' if i % 3 == 1 else 'HOLD'),
                    'net_score': np.random.uniform(-1, 1),
                    'leverage': np.random.randint(1, 5),
                    'max_holding_minutes': np.random.randint(60, 240),
                    'meta': {
                        'synergy_meta': {
                            'confidence': np.random.choice(['HIGH', 'MEDIUM', 'LOW']),
                            'buy_score': np.random.uniform(0, 1),
                            'sell_score': np.random.uniform(0, 1),
                            'conflicts_detected': []
                        }
                    }
                },
                'MEDIUM_TERM': {'action': 'HOLD', 'net_score': 0.0, 'leverage': 1, 'max_holding_minutes': 240, 'meta': {'synergy_meta': {'confidence': 'LOW', 'buy_score': 0.0, 'sell_score': 0.0}}},
                'LONG_TERM': {'action': 'HOLD', 'net_score': 0.0, 'leverage': 1, 'max_holding_minutes': 1440, 'meta': {'synergy_meta': {'confidence': 'LOW', 'buy_score': 0.0, 'sell_score': 0.0}}}
            },
            'conflicts': {'has_conflicts': False, 'long_categories': [], 'short_categories': []},
            'meta': {'active_positions': 0}
        }
        
        print(f"\nâ° ê±°ë˜ ê¸°íšŒ {i+1}")
        
        # ê°€ê²© ë°ì´í„° ì—…ë°ì´íŠ¸
        live_agent.update_price(current_ohlcv)
        
        # AI ê±°ë˜ ê²°ì •
        decision = live_agent.make_trading_decision(current_signals, current_ohlcv['close'])
        
        # ê±°ë˜ ì‹¤í–‰
        live_agent.execute_decision(decision)
        
        # ê²°ê³¼ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” ê±°ë˜ì†Œì—ì„œ ë°›ì•„ì˜´)
        if decision['action'] != 'HOLD':
            simulated_pnl = np.random.uniform(-50, 100)  # ëœë¤ ì†ìµ
            live_agent.update_trade_result(simulated_pnl)

def integrate_with_your_system():
    """ë‹¹ì‹ ì˜ ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ í†µí•© ë°©ë²•"""
    
    print("""
    ğŸ”— ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ í†µí•© ë°©ë²•:
    
    1. strategy_executor.pyì—ì„œ:
    ```python
    # ì „ëµ ì‹¤í–‰ í›„
    signals = strategy_executor.get_signals()
    
    # AI ì—ì´ì „íŠ¸ì— ì „ë‹¬
    decision = live_agent.make_trading_decision(signals, current_price)
    
    # ê±°ë˜ ì‹¤í–‰
    if decision['action'] != 'HOLD':
        execute_trade(decision)
    ```
    
    2. ì‹¤ì‹œê°„ ë£¨í”„ì—ì„œ:
    ```python
    while True:
        # 1. ìƒˆë¡œìš´ ìº”ë“¤ ë°ì´í„° ë°›ê¸°
        new_candle = get_latest_candle()
        live_agent.update_price(new_candle)
        
        # 2. ì „ëµ ì‹ í˜¸ ìƒì„±
        signals = generate_strategy_signals()
        
        # 3. AI ê²°ì • ë°›ê¸°
        decision = live_agent.make_trading_decision(signals, new_candle['close'])
        
        # 4. ê±°ë˜ ì‹¤í–‰
        if decision['action'] != 'HOLD':
            result = execute_real_trade(decision)
            live_agent.update_trade_result(result['pnl'])
        
        time.sleep(180)  # 3ë¶„ ëŒ€ê¸°
    ```
    """)

if __name__ == "__main__":
    example_live_trading()
    integrate_with_your_system()
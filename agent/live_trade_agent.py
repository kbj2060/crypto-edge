# ìˆ˜ì •ëœ ì‹¤ì‹œê°„ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ - ê¸°ì¡´ ì‹ í˜¸ ë°ì´í„° í™œìš©

import numpy as np
import pandas as pd
import torch
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
import json

from agent.ai import ImprovedCryptoRLAgent

class LiveTradingAgent:
    """ì‹¤ì‹œê°„ ê±°ë˜ë¥¼ ìœ„í•œ ì—ì´ì „íŠ¸ - ê¸°ì¡´ ì‹ í˜¸ ë°ì´í„° í™œìš©"""
    
    def __init__(self, model_path: str, initial_balance: float = 10000.0):
        """
        Args:
            model_path: í›ˆë ¨ëœ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
            initial_balance: ì‹œì‘ ì”ê³ 
        """
        self.model_path = model_path
        self.initial_balance = initial_balance
        
        # í¬íŠ¸í´ë¦¬ì˜¤ ìƒíƒœ
        self.current_balance = initial_balance
        self.current_position = 0.0
        self.current_leverage = 1.0
        self.entry_price = 0.0
        self.holding_time = 0
        self.in_position = False
        
        # ê±°ë˜ í†µê³„
        self.total_trades = 0
        self.winning_trades = 0
        self.max_drawdown = 0.0
        self.peak_balance = initial_balance
        self.consecutive_losses = 0
        
        # ê°€ê²© ì •ë³´ (ìµœì†Œí•œë§Œ ìœ ì§€)
        self.current_price = 0.0
        self.last_candle = None
        
        # í›ˆë ¨ëœ ì—ì´ì „íŠ¸ ë¡œë“œ
        self.agent = self._load_trained_agent()
        
        print(f"âœ… ì‹¤ì‹œê°„ íŠ¸ë ˆì´ë”© ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   ëª¨ë¸: {model_path}")
        print(f"   ì´ˆê¸° ì”ê³ : ${initial_balance:,.2f}")
    
    def _load_trained_agent(self):
        """í›ˆë ¨ëœ ì—ì´ì „íŠ¸ ë¡œë“œ"""
        try:
            # ì—ì´ì „íŠ¸ ìƒì„± (ìƒíƒœ í¬ê¸°ëŠ” 60ìœ¼ë¡œ ê³ ì •)
            agent = ImprovedCryptoRLAgent(state_size=60)
            
            # ëª¨ë¸ ë¡œë“œ
            if agent.safe_load_model(self.model_path):
                agent.epsilon = 0.0  # ì‹¤ê±°ë˜ì—ì„œëŠ” íƒí—˜ ë¹„í™œì„±í™”
                print(f"âœ… í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
                return agent
            else:
                raise Exception("ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
                
        except Exception as e:
            print(f"âŒ ì—ì´ì „íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def make_trading_decision(self, 
                            signal_data: Dict[str, Any], 
                            current_candle: Dict[str, float]) -> Dict[str, Any]:
        """
        ì‹¤ì‹œê°„ ê±°ë˜ ê²°ì • ìƒì„±
        
        Args:
            signal_data: ì „ëµì—ì„œ ìƒì„±ëœ ì‹ í˜¸ (parquet í˜•íƒœ ë˜ëŠ” ì¤‘ì²© ë”•ì…”ë„ˆë¦¬)
            current_candle: í˜„ì¬ ìº”ë“¤ ë°ì´í„° {'open', 'high', 'low', 'close', 'volume'}
            
        Returns:
            ê±°ë˜ ê²°ì • ë”•ì…”ë„ˆë¦¬
        """
        
        if self.agent is None:
            return self._get_default_decision("ì—ì´ì „íŠ¸ ë¡œë“œ ì‹¤íŒ¨")
        
        self.current_price = current_candle['close']
        self.last_candle = current_candle
        
        try:
            # 1. ì‹ í˜¸ ë°ì´í„°ë¥¼ í›ˆë ¨ëœ í˜•íƒœë¡œ ë³€í™˜
            state_vector = self._convert_signal_to_state(signal_data, current_candle)
            
            # 2. AI ì—ì´ì „íŠ¸ì˜ ì•¡ì…˜ ì˜ˆì¸¡
            ai_action = self.agent.act(state_vector)
            
            # 3. ì•¡ì…˜ì„ ê±°ë˜ ê²°ì •ìœ¼ë¡œ ë³€í™˜
            trading_decision = self._convert_action_to_decision(ai_action, signal_data)
            
            # 4. ë¦¬ìŠ¤í¬ ì²´í¬ ë° ìµœì¢… ê²°ì •
            final_decision = self._apply_risk_controls(trading_decision)
            
            return final_decision
            
        except Exception as e:
            print(f"âŒ ê±°ë˜ ê²°ì • ìƒì„± ì˜¤ë¥˜: {e}")
            return self._get_default_decision(f"ì˜¤ë¥˜: {str(e)}")
    
    def _convert_signal_to_state(self, signal_data: Dict, current_candle: Dict) -> np.ndarray:
        """ì‹ í˜¸ ë°ì´í„°ë¥¼ í›ˆë ¨ëœ ìƒíƒœ ë²¡í„° í˜•íƒœë¡œ ë³€í™˜"""
        
        # 1. ê°€ê²© íŠ¹ì„± (20ê°œ) - í˜„ì¬ ìº”ë“¤ ì •ë³´ í™œìš©
        price_features = self._extract_price_features_simple(current_candle)
        
        # 2. ì‹ í˜¸ íŠ¹ì„± (30ê°œ) - ê¸°ì¡´ ì‹ í˜¸ ë°ì´í„° í™œìš©
        signal_features = self._extract_signal_features(signal_data)
        
        # 3. í¬íŠ¸í´ë¦¬ì˜¤ íŠ¹ì„± (10ê°œ)
        portfolio_features = self._extract_portfolio_features()
        
        # ëª¨ë“  íŠ¹ì„± ê²°í•©
        state = np.concatenate([price_features, signal_features, portfolio_features])
        
        return state.astype(np.float32)
    
    def _extract_price_features_simple(self, candle: Dict) -> np.ndarray:
        """í˜„ì¬ ìº”ë“¤ì—ì„œ ê°„ë‹¨í•œ ê°€ê²© íŠ¹ì„± ì¶”ì¶œ"""
        
        # í˜„ì¬ ìº”ë“¤ë§Œìœ¼ë¡œ ê³„ì‚° ê°€ëŠ¥í•œ íŠ¹ì„±ë“¤
        high = candle['high']
        low = candle['low'] 
        close = candle['close']
        open_price = candle['open']
        volume = candle.get('volume', 0)
        
        # ê¸°ë³¸ íŠ¹ì„±ë“¤
        price_change = (close - open_price) / open_price if open_price > 0 else 0.0
        price_range = (high - low) / close if close > 0 else 0.0
        
        # 20ê°œ íŠ¹ì„± êµ¬ì„± (ì‹¤ì œ ê³„ì‚°ëœ ê°’ì´ ìˆìœ¼ë©´ ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ ì¤‘ë¦½ê°’)
        features = [
            price_change,        # í˜„ì¬ ìº”ë“¤ ìˆ˜ìµë¥ 
            price_range,         # ë³€ë™ì„± ëŒ€ë¦¬ê°’
            0.0,                 # returns_mean (ì¤‘ë¦½)
            price_range,         # returns_std ëŒ€ì‹  price_range
            0.5,                 # RSI (ì¤‘ë¦½ê°’ - ì‹¤ì œ ê³„ì‚°ì€ signal_dataì—ì„œ)
            0.5,                 # BB position (ì¤‘ë¦½ê°’)
            0.0, 0.0, 0.0,       # MA ratios (ì¤‘ë¦½ê°’)
            0.0,                 # volume ratio (ê³„ì‚° ë³µì¡)
            price_range,         # volatility
            0.0,                 # price position
            0.0, 0.0, 0.0, 0.0,  # ì¶”ê°€ ê¸°ìˆ ì  ì§€í‘œë“¤
            0.0, 0.0, 0.0, 0.0, 0.0  # ë‚˜ë¨¸ì§€ íŒ¨ë”©
        ]
        
        return np.array(features[:20], dtype=np.float32)
    
    def _extract_signal_features(self, signal_data: Dict) -> np.ndarray:
        """ì‹ í˜¸ ë°ì´í„°ì—ì„œ íŠ¹ì„± ì¶”ì¶œ (í›ˆë ¨ ì‹œì™€ ë™ì¼í•œ ë¡œì§)"""
        features = []
        
        # ì‹ í˜¸ ë°ì´í„° í˜•íƒœ í™•ì¸ ë° í‘œì¤€í™”
        decisions = self._normalize_signal_data(signal_data)
        
        # ê° ì‹œê°„ëŒ€ë³„ ì‹ í˜¸ íŠ¹ì„± (3ê°œ Ã— 8ê°œ = 24ê°œ)
        for category in ['SHORT_TERM', 'MEDIUM_TERM', 'LONG_TERM']:
            if category in decisions:
                decision = decisions[category]
                
                action = decision.get('action', 'HOLD')
                action_strength = 1.0 if action == 'LONG' else (-1.0 if action == 'SHORT' else 0.0)
                
                features.extend([
                    action_strength,
                    float(decision.get('net_score', 0.0)),
                    min(float(decision.get('leverage', 1)) / 10.0, 2.0),
                    min(float(decision.get('max_holding_minutes', 60)) / 1440.0, 1.0),
                ])
                
                # ë©”íƒ€ ì •ë³´
                meta = decision.get('meta', {}).get('synergy_meta', {})
                confidence = meta.get('confidence', 'LOW')
                confidence_score = 1.0 if confidence == 'HIGH' else (0.5 if confidence == 'MEDIUM' else 0.0)
                
                features.extend([
                    confidence_score,
                    float(meta.get('buy_score', 0.0)),
                    float(meta.get('sell_score', 0.0)),
                    len(meta.get('conflicts_detected', [])) / 5.0
                ])
            else:
                features.extend([0.0] * 8)
        
        # ê°ˆë“± ë° ë©”íƒ€ ì •ë³´ (6ê°œ)
        conflicts = signal_data.get('conflicts', {})
        features.extend([
            1.0 if conflicts.get('has_conflicts', False) else 0.0,
            len(conflicts.get('long_categories', [])) / 3.0,
            len(conflicts.get('short_categories', [])) / 3.0,
            float(signal_data.get('meta', {}).get('active_positions', 0)) / 3.0,
            0.0, 0.0  # ì˜ˆë¹„
        ])
        
        return np.array(features[:30], dtype=np.float32)
    
    def _normalize_signal_data(self, signal_data: Dict) -> Dict:
        """ì‹ í˜¸ ë°ì´í„°ë¥¼ í‘œì¤€ í˜•íƒœë¡œ ë³€í™˜"""
        
        # ì´ë¯¸ ì¤‘ì²© ë”•ì…”ë„ˆë¦¬ í˜•íƒœì¸ ê²½ìš° (ai.pyì™€ ë™ì¼)
        if 'decisions' in signal_data:
            return signal_data['decisions']
        
        # parquet í‰ë©´í™”ëœ í˜•íƒœì¸ ê²½ìš° (agent.pyì™€ ë™ì¼)
        decisions = {}
        
        for category in ['SHORT_TERM', 'MEDIUM_TERM', 'LONG_TERM']:
            prefix = f"{category.lower()}_"
            
            decisions[category] = {
                'action': signal_data.get(f'{prefix}action', 'HOLD'),
                'net_score': float(signal_data.get(f'{prefix}net_score', 0.0)),
                'leverage': int(signal_data.get(f'{prefix}leverage', 1)),
                'max_holding_minutes': int(signal_data.get(f'{prefix}max_holding_minutes', 60)),
                'meta': {
                    'synergy_meta': {
                        'confidence': signal_data.get(f'{prefix}confidence', 'LOW'),
                        'buy_score': float(signal_data.get(f'{prefix}buy_score', 0.0)),
                        'sell_score': float(signal_data.get(f'{prefix}sell_score', 0.0)),
                        'conflicts_detected': []
                    }
                }
            }
        
        return decisions
    
    def _extract_portfolio_features(self) -> np.ndarray:
        """í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ ìƒíƒœ íŠ¹ì„±"""
        features = [
            self.current_position,
            self.current_leverage / 20.0,
            (self.current_balance - self.initial_balance) / self.initial_balance,
            0.0,  # unrealized_pnl (ë‹¨ìˆœí™”)
            min(self.total_trades / 100.0, 1.0),
            self.winning_trades / max(self.total_trades, 1),
            self.max_drawdown,
            min(self.consecutive_losses / 10.0, 1.0),
            min(self.holding_time / 1440.0, 1.0),
            1.0 if self.in_position else 0.0
        ]
        return np.array(features, dtype=np.float32)
    
    def _convert_action_to_decision(self, ai_action: np.ndarray, signal_data: Dict) -> Dict[str, Any]:
        """AI ì•¡ì…˜ì„ ì‹¤ì œ ê±°ë˜ ê²°ì •ìœ¼ë¡œ ë³€í™˜"""
        
        position_change = ai_action[0]
        leverage = ai_action[1] 
        holding_minutes = ai_action[2]
        
        # ì‹ í˜¸ í’ˆì§ˆ ë¶„ì„
        signal_quality = self._analyze_signal_quality(signal_data)
        
        # ê±°ë˜ ê²°ì • ìƒì„±
        decision = {
            'timestamp': datetime.now(),
            'current_price': self.current_price,
            'ai_confidence': self._calculate_confidence(ai_action, signal_quality),
            'signal_quality': signal_quality,
            'position_change': position_change,
            'target_leverage': min(leverage, 5.0),  # ìµœëŒ€ 5ë°°ë¡œ ì œí•œ
            'target_holding_minutes': holding_minutes,
            'action': 'HOLD',
            'reason': '',
            'quantity': 0.0,
            'stop_loss': None,
            'take_profit': None
        }
        
        # ì•¡ì…˜ í•´ì„ (ë” ë³´ìˆ˜ì ìœ¼ë¡œ)
        min_threshold = 0.2  # ìµœì†Œ ì„ê³„ê°’ ì¦ê°€
        
        if abs(position_change) > min_threshold and signal_quality['overall_score'] > 0.3:
            if position_change > min_threshold:
                decision['action'] = 'BUY'
                decision['reason'] = f"AI+ì‹ í˜¸ ì¶”ì²œ: Long {position_change:.2f} (í’ˆì§ˆ: {signal_quality['overall_score']:.2f})"
            elif position_change < -min_threshold:
                decision['action'] = 'SELL'  
                decision['reason'] = f"AI+ì‹ í˜¸ ì¶”ì²œ: Short {abs(position_change):.2f} (í’ˆì§ˆ: {signal_quality['overall_score']:.2f})"
            
            # í¬ì§€ì…˜ í¬ê¸° ê³„ì‚° (ì‹ í˜¸ í’ˆì§ˆ ë°˜ì˜)
            decision['quantity'] = self._calculate_position_size(
                position_change, leverage, signal_quality['overall_score']
            )
            
            # ìŠ¤íƒ‘ ì„¤ì •
            decision['stop_loss'], decision['take_profit'] = self._calculate_stops(
                decision['action'], holding_minutes, signal_quality
            )
        else:
            decision['reason'] = f"ì„ê³„ê°’ ë¯¸ë‹¬ (ë³€ê²½ëŸ‰: {position_change:.2f}, ì‹ í˜¸í’ˆì§ˆ: {signal_quality['overall_score']:.2f})"
        
        return decision
    
    def _analyze_signal_quality(self, signal_data: Dict) -> Dict:
        """ì‹ í˜¸ ë°ì´í„° í’ˆì§ˆ ë¶„ì„"""
        decisions = self._normalize_signal_data(signal_data)
        
        quality_metrics = {
            'high_confidence_signals': 0,
            'total_signals': 0,
            'agreement_score': 0.0,
            'overall_score': 0.0
        }
        
        actions = []
        confidences = []
        
        for category in ['SHORT_TERM', 'MEDIUM_TERM', 'LONG_TERM']:
            if category in decisions:
                decision = decisions[category]
                action = decision.get('action', 'HOLD')
                confidence = decision.get('meta', {}).get('synergy_meta', {}).get('confidence', 'LOW')
                
                if action != 'HOLD':
                    quality_metrics['total_signals'] += 1
                    actions.append(1 if action == 'LONG' else -1)
                    
                    if confidence == 'HIGH':
                        quality_metrics['high_confidence_signals'] += 1
                        confidences.append(1.0)
                    elif confidence == 'MEDIUM':
                        confidences.append(0.5)
                    else:
                        confidences.append(0.1)
        
        # ì‹ í˜¸ ì¼ì¹˜ë„ ê³„ì‚°
        if actions:
            action_agreement = 1.0 - (np.std(actions) if len(actions) > 1 else 0.0)
            avg_confidence = np.mean(confidences)
            
            quality_metrics['agreement_score'] = action_agreement
            quality_metrics['overall_score'] = (action_agreement + avg_confidence) / 2
        
        return quality_metrics
    
    def _calculate_confidence(self, ai_action: np.ndarray, signal_quality: Dict) -> float:
        """AIì™€ ì‹ í˜¸ í’ˆì§ˆì„ ê²°í•©í•œ ì‹ ë¢°ë„ ê³„ì‚°"""
        
        # AI ì‹ ë¢°ë„
        ai_confidence = min(abs(ai_action[0]) / 2.0, 1.0)
        
        # ì‹ í˜¸ í’ˆì§ˆ ì‹ ë¢°ë„
        signal_confidence = signal_quality['overall_score']
        
        # ê²°í•© ì‹ ë¢°ë„ (ê°€ì¤‘í‰ê· )
        combined_confidence = (ai_confidence * 0.6) + (signal_confidence * 0.4)
        
        return min(combined_confidence, 1.0)
    
    def _calculate_position_size(self, position_change: float, leverage: float, signal_quality: float) -> float:
        """í¬ì§€ì…˜ í¬ê¸° ê³„ì‚° (ì‹ í˜¸ í’ˆì§ˆ ë°˜ì˜)"""
        
        # ê¸°ë³¸ ë¦¬ìŠ¤í¬ (ì”ê³ ì˜ 1-3%)
        base_risk_pct = 0.01 + (signal_quality * 0.02)  # 1-3%
        base_risk = self.current_balance * base_risk_pct
        
        # í¬ì§€ì…˜ ë³€ê²½ëŸ‰ ë°˜ì˜
        position_multiplier = min(abs(position_change), 1.0)
        
        # ë ˆë²„ë¦¬ì§€ ì œí•œ
        safe_leverage = min(leverage, 3.0)  # ë” ë³´ìˆ˜ì 
        
        # ìµœì¢… í¬ì§€ì…˜ í¬ê¸°
        position_usd = base_risk * position_multiplier * safe_leverage
        
        # ìµœëŒ€ ì”ê³ ì˜ 15%ë¡œ ì œí•œ
        max_position = self.current_balance * 0.15
        
        return min(position_usd, max_position)
    
    def _calculate_stops(self, action: str, holding_minutes: float, signal_quality: Dict) -> Tuple[Optional[float], Optional[float]]:
        """ìŠ¤íƒ‘ë¡œìŠ¤ì™€ ìµì ˆê°€ ê³„ì‚°"""
        
        if action == 'HOLD':
            return None, None
        
        # ATR ëŒ€ì‹  ìº”ë“¤ ì •ë³´ í™œìš©
        if self.last_candle:
            price_range = (self.last_candle['high'] - self.last_candle['low']) / self.current_price
            volatility_estimate = max(price_range, 0.01)  # ìµœì†Œ 1%
        else:
            volatility_estimate = 0.02  # ê¸°ë³¸ 2%
        
        # ì‹ í˜¸ í’ˆì§ˆì— ë”°ë¥¸ ìŠ¤íƒ‘ ì¡°ì •
        stop_multiplier = 1.5 + (1.0 - signal_quality['overall_score'])  # í’ˆì§ˆ ë‚®ìœ¼ë©´ íƒ€ì´íŠ¸í•˜ê²Œ
        profit_multiplier = 1.0 + signal_quality['overall_score']  # í’ˆì§ˆ ë†’ìœ¼ë©´ ë” í° ëª©í‘œ
        
        if action == 'BUY':
            stop_loss = self.current_price * (1 - volatility_estimate * stop_multiplier)
            take_profit = self.current_price * (1 + volatility_estimate * profit_multiplier)
        else:  # SELL
            stop_loss = self.current_price * (1 + volatility_estimate * stop_multiplier)
            take_profit = self.current_price * (1 - volatility_estimate * profit_multiplier)
        
        return stop_loss, take_profit
    
    def _apply_risk_controls(self, decision: Dict[str, Any]) -> Dict[str, Any]:
        """ìµœì¢… ë¦¬ìŠ¤í¬ ì²´í¬"""
        
        # 1. ìµœëŒ€ ë“œë¡œìš°ë‹¤ìš´ ì²´í¬
        current_drawdown = (self.peak_balance - self.current_balance) / self.peak_balance if self.peak_balance > 0 else 0
        if current_drawdown > 0.12:  # 12% ì´ìƒ ì†ì‹¤ì‹œ
            decision['action'] = 'HOLD'
            decision['reason'] = f"ë¦¬ìŠ¤í¬ ê´€ë¦¬: ìµœëŒ€ ì†ì‹¤ í•œë„ ({current_drawdown:.1%})"
            decision['quantity'] = 0.0
            return decision
        
        # 2. ì—°ì† ì†ì‹¤ ì²´í¬
        if self.consecutive_losses > 3:
            decision['quantity'] *= 0.5
            decision['reason'] += f" (ì—°ì†ì†ì‹¤ {self.consecutive_losses}íšŒ, í¬ê¸° ê°ì†Œ)"
        
        # 3. ì‹ ë¢°ë„ ì²´í¬
        if decision['ai_confidence'] < 0.4:
            decision['action'] = 'HOLD'
            decision['reason'] = f"ì‹ ë¢°ë„ ë¶€ì¡± ({decision['ai_confidence']:.2f})"
            decision['quantity'] = 0.0
        
        # 4. í¬ì§€ì…˜ í¬ê¸° ìµœì¢… ê²€ì¦
        if decision['quantity'] > self.current_balance * 0.2:
            decision['quantity'] = self.current_balance * 0.2
            decision['reason'] += " (í¬ì§€ì…˜ í¬ê¸° ì œí•œ)"
        
        return decision
    
    def _get_default_decision(self, reason: str) -> Dict[str, Any]:
        """ê¸°ë³¸ ê²°ì • (ê±°ë˜ ì•ˆí•¨)"""
        return {
            'timestamp': datetime.now(),
            'action': 'HOLD',
            'reason': reason,
            'quantity': 0.0,
            'ai_confidence': 0.0,
            'signal_quality': {'overall_score': 0.0},
            'stop_loss': None,
            'take_profit': None
        }
    
    def execute_decision(self, decision: Dict[str, Any]) -> bool:
        """ê±°ë˜ ê²°ì • ì‹¤í–‰"""
        
        if decision['action'] == 'HOLD':
            print(f"â¸ï¸  ê±°ë˜ ì—†ìŒ: {decision['reason']}")
            return True
        
        print(f"\nğŸ“Š AI ê±°ë˜ ê²°ì •:")
        print(f"   ì•¡ì…˜: {decision['action']}")
        print(f"   ìˆ˜ëŸ‰: ${decision['quantity']:.2f}")
        print(f"   AI ì‹ ë¢°ë„: {decision['ai_confidence']:.2f}")
        print(f"   ì‹ í˜¸ í’ˆì§ˆ: {decision['signal_quality']['overall_score']:.2f}")
        print(f"   ìŠ¤íƒ‘ë¡œìŠ¤: ${decision['stop_loss']:.2f}" if decision['stop_loss'] else "   ìŠ¤íƒ‘ë¡œìŠ¤: ì—†ìŒ")
        print(f"   ìµì ˆê°€: ${decision['take_profit']:.2f}" if decision['take_profit'] else "   ìµì ˆê°€: ì—†ìŒ")
        print(f"   ì´ìœ : {decision['reason']}")
        
        # ì‹¤ì œ ê±°ë˜ì†Œ API í˜¸ì¶œì€ ì—¬ê¸°ì— êµ¬í˜„
        # result = exchange_api.place_order(...)
        
        return True
    
    def update_trade_result(self, trade_pnl: float):
        """ê±°ë˜ ê²°ê³¼ ì—…ë°ì´íŠ¸"""
        self.total_trades += 1
        
        if trade_pnl > 0:
            self.winning_trades += 1
            self.consecutive_losses = 0
            print(f"âœ… ìˆ˜ìµ ê±°ë˜: +${trade_pnl:.2f}")
        else:
            self.consecutive_losses += 1
            print(f"âŒ ì†ì‹¤ ê±°ë˜: ${trade_pnl:.2f}")
        
        # ì”ê³  ë° í†µê³„ ì—…ë°ì´íŠ¸
        self.current_balance += trade_pnl
        
        if self.current_balance > self.peak_balance:
            self.peak_balance = self.current_balance
        else:
            drawdown = (self.peak_balance - self.current_balance) / self.peak_balance
            self.max_drawdown = max(self.max_drawdown, drawdown)
        
        # í†µê³„ ì¶œë ¥
        win_rate = self.winning_trades / self.total_trades
        total_return = (self.current_balance - self.initial_balance) / self.initial_balance
        
        print(f"ğŸ“ˆ í˜„ì¬ í†µê³„: ìŠ¹ë¥  {win_rate:.1%}, ìˆ˜ìµë¥  {total_return:.1%}, ì”ê³  ${self.current_balance:.2f}")

# =================================================================
# ì‚¬ìš© ì˜ˆì‹œ (ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ í†µí•©)
# =================================================================

def integrate_with_strategy_executor():
    """ê¸°ì¡´ strategy_executorì™€ì˜ í†µí•© ì˜ˆì‹œ"""
    
    print("""
    ğŸ”— ê¸°ì¡´ ì‹œìŠ¤í…œ í†µí•© ë°©ë²•:

    1. main.pyì—ì„œ:
    ```python
    from agent.live_trade_agent import LiveTradingAgent
    
    # AI ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
    live_agent = LiveTradingAgent('agent/final_optimized_model.pth')
    
    # ë©”ì¸ ë£¨í”„ì—ì„œ
    while True:
        # ê¸°ì¡´ ì „ëµ ì‹¤í–‰
        strategy_executor.execute_all_strategies()
        signals = strategy_executor.get_signals()
        decision = decision_engine.decide_trade_realtime(signals)
        
        # AI ì—ì´ì „íŠ¸ ê²°ì • ì¶”ê°€
        current_candle = get_current_candle()
        ai_decision = live_agent.make_trading_decision(decision, current_candle)
        
        # ìµœì¢… ê±°ë˜ ì‹¤í–‰
        if ai_decision['action'] != 'HOLD':
            execute_trade(ai_decision)
            
        time.sleep(180)  # 3ë¶„ ëŒ€ê¸°
    ```
    
    2. decision_engine.pyì—ì„œ AI ê²°ì • í†µí•©:
    ```python
    def decide_trade_with_ai(self, signals, ai_agent, current_candle):
        # ê¸°ì¡´ ê²°ì •
        base_decision = self.decide_trade_realtime(signals)
        
        # AI ê²°ì •
        ai_decision = ai_agent.make_trading_decision(base_decision, current_candle)
        
        # ê²°í•© ë¡œì§ (ì˜ˆ: AIê°€ HOLDì´ë©´ ê¸°ì¡´ ê²°ì •, AIê°€ ê±°ë˜ë©´ AI ìš°ì„ )
        if ai_decision['action'] != 'HOLD':
            return ai_decision
        else:
            return base_decision
    ```
    """)

def example_usage():
    """ì‚¬ìš© ì˜ˆì‹œ"""
    
    # AI ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
    agent = LiveTradingAgent('agent/final_optimized_model.pth')
    
    # ê°€ìƒì˜ ì‹ í˜¸ ë°ì´í„° (ì‹¤ì œë¡œëŠ” strategy_executorì—ì„œ)
    signal_data = {
        'decisions': {
            'SHORT_TERM': {
                'action': 'LONG',
                'net_score': 0.7,
                'leverage': 3,
                'max_holding_minutes': 120,
                'meta': {
                    'synergy_meta': {
                        'confidence': 'HIGH',
                        'buy_score': 0.8,
                        'sell_score': 0.1,
                        'conflicts_detected': []
                    }
                }
            },
            'MEDIUM_TERM': {'action': 'HOLD', 'net_score': 0.0, 'leverage': 1, 'max_holding_minutes': 240, 'meta': {'synergy_meta': {'confidence': 'LOW'}}},
            'LONG_TERM': {'action': 'HOLD', 'net_score': 0.0, 'leverage': 1, 'max_holding_minutes': 1440, 'meta': {'synergy_meta': {'confidence': 'LOW'}}}
        },
        'conflicts': {'has_conflicts': False},
        'meta': {'active_positions': 0}
    }
    
    current_candle = {
        'open': 3000,
        'high': 3010,
        'low': 2995,
        'close': 3005,
        'volume': 1000000
    }
    
    # ê±°ë˜ ê²°ì •
    decision = agent.make_trading_decision(signal_data, current_candle)
    print(f"AI ê²°ì •: {decision}")
    
    # ê±°ë˜ ì‹¤í–‰
    agent.execute_decision(decision)

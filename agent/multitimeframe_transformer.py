"""
Multi-Timeframe Transformer ë”¥ëŸ¬ë‹ ëª¨ë¸
- Decision ë°ì´í„°ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ì„œ ì˜ì‚¬ê²°ì •ì„ ìˆ˜í–‰
- ë‹¤ì¤‘ ì‹œê°„í”„ë ˆì„ ë¶„ì„ (3m, 15m, 1h)
- Transformer ê¸°ë°˜ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜
- ìˆ˜ìµë¥  ìµœì í™” ì¤‘ì‹¬ ì„¤ê³„
"""

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import random
import os
from datetime import datetime
from typing import Dict, List, Tuple, Any, Optional
from pathlib import Path
import json
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import mean_absolute_error, accuracy_score

# PyTorch í˜¸í™˜ì„± ì„¤ì •
def setup_pytorch_compatibility():
    """PyTorch ë²„ì „ í˜¸í™˜ì„± ì„¤ì •"""
    try:
        safe_globals = [
            np.ndarray, np.dtype, np.float32, np.float64, np.int32, np.int64,
        ]
        
        try:
            import numpy._core.multiarray
            safe_globals.append(numpy._core.multiarray.scalar)
        except ImportError:
            try:
                import numpy.core.multiarray
                safe_globals.append(numpy.core.multiarray.scalar)
            except ImportError:
                pass
        
        torch.serialization.add_safe_globals(safe_globals)
        print("PyTorch í˜¸í™˜ ì„¤ì • ì™„ë£Œ (NumPy 2.0 í˜¸í™˜)")
    except AttributeError:
        print("PyTorch ì´ì „ ë²„ì „ ê°ì§€ë¨")

setup_pytorch_compatibility()

class DataNormalizer:
    """ë°ì´í„° ì •ê·œí™” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.scalers = {}
        self.is_fitted = False
    
    def fit_transform(self, data_list: List[Dict]) -> List[Dict]:
        """ë°ì´í„° ì •ê·œí™” ì ìš©"""
        if not data_list:
            return data_list
        
        # íŠ¹ì„±ë³„ë¡œ ë¶„ë¥˜
        price_features = ['open', 'high', 'low', 'close', 'volume', 'quote_volume']
        indicator_features = [f'indicator_{col}' for col in [
            'vwap', 'atr', 'poc', 'hvn', 'lvn', 'vwap_std',
            'prev_day_high', 'prev_day_low', 'opening_range_high', 'opening_range_low'
        ]]
        score_features = [col for col in data_list[0].keys() if col.endswith('_score')]
        entry_stop_features = [col for col in data_list[0].keys() if col.endswith('_entry') or col.endswith('_stop')]
        
        # ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
        price_data = np.array([[float(data.get(f, 0.0)) for f in price_features] for data in data_list])
        indicator_data = np.array([[float(data.get(f, 0.0)) for f in indicator_features] for data in data_list])
        score_data = np.array([[float(data.get(f, 0.0)) for f in score_features] for data in data_list])
        entry_stop_data = np.array([[float(data.get(f, 0.0)) for f in entry_stop_features] for data in data_list])
        
        # ê°€ê²© ë°ì´í„°: Min-Max ì •ê·œí™” (0-1 ë²”ìœ„)
        self.scalers['price'] = MinMaxScaler()
        price_normalized = self.scalers['price'].fit_transform(price_data)
        
        # ì§€í‘œ ë°ì´í„°: Standard ì •ê·œí™”
        self.scalers['indicator'] = StandardScaler()
        indicator_normalized = self.scalers['indicator'].fit_transform(indicator_data)
        
        # ì ìˆ˜ ë°ì´í„°: Min-Max ì •ê·œí™” (0-1 ë²”ìœ„)
        self.scalers['score'] = MinMaxScaler()
        score_normalized = self.scalers['score'].fit_transform(score_data)
        
        # Entry/Stop ë°ì´í„°: Min-Max ì •ê·œí™” (0-1 ë²”ìœ„)
        self.scalers['entry_stop'] = MinMaxScaler()
        entry_stop_normalized = self.scalers['entry_stop'].fit_transform(entry_stop_data)
        
        # ì •ê·œí™”ëœ ë°ì´í„°ë¥¼ ì›ë³¸ í˜•íƒœë¡œ ë³µì›
        normalized_data = []
        for i, data in enumerate(data_list):
            normalized_item = data.copy()
            
            # ê°€ê²© ë°ì´í„° ì •ê·œí™”
            for j, feature in enumerate(price_features):
                normalized_item[feature] = price_normalized[i][j]
            
            # ì§€í‘œ ë°ì´í„° ì •ê·œí™”
            for j, feature in enumerate(indicator_features):
                normalized_item[feature] = indicator_normalized[i][j]
            
            # ì ìˆ˜ ë°ì´í„° ì •ê·œí™”
            for j, feature in enumerate(score_features):
                normalized_item[feature] = score_normalized[i][j]
            
            # Entry/Stop ë°ì´í„° ì •ê·œí™”
            for j, feature in enumerate(entry_stop_features):
                normalized_item[feature] = entry_stop_normalized[i][j]
            
            normalized_data.append(normalized_item)
        
        self.is_fitted = True
        return normalized_data
    
    def transform(self, data_list: List[Dict]) -> List[Dict]:
        """ì´ë¯¸ í”¼íŒ…ëœ ìŠ¤ì¼€ì¼ëŸ¬ë¡œ ì •ê·œí™” ì ìš© (fit ì—†ì´)"""
        if not self.is_fitted:
            raise ValueError("ìŠ¤ì¼€ì¼ëŸ¬ê°€ í”¼íŒ…ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. fit_transformì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
        
        if not data_list:
            return data_list
        
        # íŠ¹ì„±ë³„ë¡œ ë¶„ë¥˜ (fit_transformê³¼ ë™ì¼)
        price_features = ['open', 'high', 'low', 'close', 'volume', 'quote_volume']
        indicator_features = [f'indicator_{col}' for col in [
            'vwap', 'atr', 'poc', 'hvn', 'lvn', 'vwap_std',
            'prev_day_high', 'prev_day_low', 'opening_range_high', 'opening_range_low'
        ]]
        score_features = [col for col in data_list[0].keys() if col.endswith('_score')]
        entry_stop_features = [col for col in data_list[0].keys() if col.endswith('_entry') or col.endswith('_stop')]
        
        # ë°ì´í„°ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
        price_data = np.array([[float(data.get(f, 0.0)) for f in price_features] for data in data_list])
        indicator_data = np.array([[float(data.get(f, 0.0)) for f in indicator_features] for data in data_list])
        score_data = np.array([[float(data.get(f, 0.0)) for f in score_features] for data in data_list])
        entry_stop_data = np.array([[float(data.get(f, 0.0)) for f in entry_stop_features] for data in data_list])
        
        # ì´ë¯¸ í”¼íŒ…ëœ ìŠ¤ì¼€ì¼ëŸ¬ë¡œ transformë§Œ ìˆ˜í–‰
        price_normalized = self.scalers['price'].transform(price_data)
        indicator_normalized = self.scalers['indicator'].transform(indicator_data)
        score_normalized = self.scalers['score'].transform(score_data)
        entry_stop_normalized = self.scalers['entry_stop'].transform(entry_stop_data)
        
        # ì •ê·œí™”ëœ ë°ì´í„°ë¥¼ ì›ë³¸ í˜•íƒœë¡œ ë³µì›
        normalized_data = []
        for i, data in enumerate(data_list):
            normalized_item = data.copy()
            
            # ê°€ê²© ë°ì´í„° ì •ê·œí™”
            for j, feature in enumerate(price_features):
                normalized_item[feature] = price_normalized[i][j]
            
            # ì§€í‘œ ë°ì´í„° ì •ê·œí™”
            for j, feature in enumerate(indicator_features):
                normalized_item[feature] = indicator_normalized[i][j]
            
            # ì ìˆ˜ ë°ì´í„° ì •ê·œí™”
            for j, feature in enumerate(score_features):
                normalized_item[feature] = score_normalized[i][j]
            
            # Entry/Stop ë°ì´í„° ì •ê·œí™”
            for j, feature in enumerate(entry_stop_features):
                normalized_item[feature] = entry_stop_normalized[i][j]
            
            normalized_data.append(normalized_item)
        
        return normalized_data

class PositionalEncoding(nn.Module):
    """ìœ„ì¹˜ ì¸ì½”ë”©"""
    def __init__(self, d_model: int, max_len: int = 5000):
        super().__init__()
        self.dropout = nn.Dropout(p=0.1)
        
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0).transpose(0, 1)
        self.register_buffer('pe', pe)
    
    def forward(self, x):
        x = x + self.pe[:x.size(0), :]
        return self.dropout(x)

class MultiTimeframeTransformer(nn.Module):
    """Multi-Timeframe Transformer ëª¨ë¸"""
    
    def __init__(self, 
                 input_size: int = 58,
                 d_model: int = 256,
                 nhead: int = 8,
                 num_layers: int = 6,
                 dropout: float = 0.1,
                 max_seq_len: int = 100):
        super().__init__()
        
        self.input_size = input_size
        self.d_model = d_model
        self.nhead = nhead
        self.num_layers = num_layers
        self.max_seq_len = max_seq_len
        
        # ì…ë ¥ ì„ë² ë”©
        self.input_embedding = nn.Sequential(
            nn.Linear(input_size, d_model),
            nn.LayerNorm(d_model),
            nn.ReLU(),
            nn.Dropout(dropout)
        )
        
        # ìœ„ì¹˜ ì¸ì½”ë”©
        self.pos_encoding = PositionalEncoding(d_model, max_seq_len)
        
        # Transformer ì¸ì½”ë”
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=d_model * 4,
            dropout=dropout,
            activation='relu',
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)
        
        # ì‹œê°„í”„ë ˆì„ë³„ íŠ¹ì„± ì¶”ì¶œê¸°
        self.timeframe_extractors = nn.ModuleDict({
            'short_term': self._build_timeframe_extractor(d_model, 'short'),
            'medium_term': self._build_timeframe_extractor(d_model, 'medium'),
            'long_term': self._build_timeframe_extractor(d_model, 'long')
        })
        
        # ì˜ì‚¬ê²°ì • í—¤ë“œë“¤ (ë‹¨ìˆœí™”: action, confidence, profitë§Œ)
        self.decision_heads = nn.ModuleDict({
            'action': nn.Sequential(
                nn.Linear(d_model, d_model // 2),
                nn.ReLU(),
                nn.LayerNorm(d_model // 2),
                nn.Dropout(dropout),
                nn.Linear(d_model // 2, 3)  # BUY, SELL, HOLD
            ),
            'confidence': nn.Sequential(
                nn.Linear(d_model, d_model // 2),
                nn.ReLU(),
                nn.LayerNorm(d_model // 2),
                nn.Dropout(dropout),
                nn.Linear(d_model // 2, 1),
                nn.Sigmoid()
            )
        })
        
        # ìˆ˜ìµë¥  ì˜ˆì¸¡ê¸°
        self.profit_predictor = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.ReLU(),
            nn.LayerNorm(d_model // 2),
            nn.Dropout(dropout),
            nn.Linear(d_model // 2, 1)
        )
        
        # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”
        self.apply(self._init_weights)
    
    def _build_timeframe_extractor(self, d_model: int, timeframe: str):
        """ì‹œê°„í”„ë ˆì„ë³„ íŠ¹ì„± ì¶”ì¶œê¸°"""
        if timeframe == 'short':
            # ë‹¨ê¸°: ë¹ ë¥¸ ë°˜ì‘, ë†’ì€ ë¯¼ê°ë„
            return nn.Sequential(
                nn.Linear(d_model, d_model // 2),
                nn.ReLU(),
                nn.LayerNorm(d_model // 2),
                nn.Dropout(0.05),  # ë‚®ì€ ë“œë¡­ì•„ì›ƒ
                nn.Linear(d_model // 2, d_model // 2)
            )
        elif timeframe == 'medium':
            # ì¤‘ê¸°: ê· í˜•ì¡íŒ ë¶„ì„
            return nn.Sequential(
                nn.Linear(d_model, d_model // 2),
                nn.ReLU(),
                nn.LayerNorm(d_model // 2),
                nn.Dropout(0.1),
                nn.Linear(d_model // 2, d_model // 2)
            )
        else:  # long
            # ì¥ê¸°: ì•ˆì •ì , ë‚®ì€ ë¯¼ê°ë„
            return nn.Sequential(
                nn.Linear(d_model, d_model // 2),
                nn.ReLU(),
                nn.LayerNorm(d_model // 2),
                nn.Dropout(0.15),  # ë†’ì€ ë“œë¡­ì•„ì›ƒ
                nn.Linear(d_model // 2, d_model // 2)
            )
    
    def _init_weights(self, module):
        """Xavier ì´ˆê¸°í™”"""
        if isinstance(module, nn.Linear):
            nn.init.xavier_uniform_(module.weight)
            nn.init.constant_(module.bias, 0)
    
    def forward(self, x, mask=None):
        """
        Args:
            x: [batch_size, seq_len, input_size] ë˜ëŠ” [batch_size, input_size]
            mask: [batch_size, seq_len] (ì„ íƒì )
        """
        # ë°°ì¹˜ ì°¨ì› í™•ì¸
        if x.dim() == 2:
            x = x.unsqueeze(1)  # [batch_size, 1, input_size]
            single_sample = True
        else:
            single_sample = False
        
        batch_size, seq_len, _ = x.shape
        
        # ì…ë ¥ ì„ë² ë”©
        x = self.input_embedding(x)  # [batch_size, seq_len, d_model]
        
        # ìœ„ì¹˜ ì¸ì½”ë”©
        x = x.transpose(0, 1)  # [seq_len, batch_size, d_model]
        x = self.pos_encoding(x)
        x = x.transpose(0, 1)  # [batch_size, seq_len, d_model]
        
        # Transformer ì¸ì½”ë”
        if mask is not None:
            # ë§ˆìŠ¤í¬ ì ìš© (íŒ¨ë”© í† í° ë“±)
            x = self.transformer(x, src_key_padding_mask=mask)
        else:
            x = self.transformer(x)
        
        # ìµœì¢… íŠ¹ì„± (ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ ìš”ì†Œ ì‚¬ìš©)
        final_features = x[:, -1, :]  # [batch_size, d_model]
        
        # ì‹œê°„í”„ë ˆì„ë³„ íŠ¹ì„± ì¶”ì¶œ
        timeframe_features = {}
        for timeframe, extractor in self.timeframe_extractors.items():
            timeframe_features[timeframe] = extractor(final_features)
        
        # ì˜ì‚¬ê²°ì • ì¶œë ¥
        decisions = {}
        for head_name, head in self.decision_heads.items():
            decisions[head_name] = head(final_features)
        
        # ìˆ˜ìµë¥  ì˜ˆì¸¡
        profit_pred = self.profit_predictor(final_features)
        
        # ë‹¨ì¼ ìƒ˜í”Œì´ë©´ ë°°ì¹˜ ì°¨ì› ì œê±°
        if single_sample:
            for key in decisions:
                decisions[key] = decisions[key].squeeze(0)
            profit_pred = profit_pred.squeeze(0)
            for key in timeframe_features:
                timeframe_features[key] = timeframe_features[key].squeeze(0)
        
        return decisions, profit_pred, timeframe_features

class MultiTimeframeDecisionEngine:
    """Multi-Timeframe ì˜ì‚¬ê²°ì • ì—”ì§„"""
    
    def __init__(self, 
                 model_path: str = 'agent/best_multitimeframe_model.pth',
                 input_size: int = 58,
                 d_model: int = 256,
                 nhead: int = 8,
                 num_layers: int = 6,
                 device: str = 'auto'):
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        if device == 'auto':
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = torch.device(device)
        
        print(f"Multi-Timeframe Transformer ë””ë°”ì´ìŠ¤: {self.device}")
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.model = MultiTimeframeTransformer(
            input_size=input_size,
            d_model=d_model,
            nhead=nhead,
            num_layers=num_layers
        ).to(self.device)
        
        # ì˜µí‹°ë§ˆì´ì €
        self.optimizer = optim.AdamW(
            self.model.parameters(),
            lr=5e-4,  # ë” ë†’ì€ í•™ìŠµë¥ 
            weight_decay=1e-5
        )
        
        # ìŠ¤ì¼€ì¤„ëŸ¬
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer,
            mode='max',
            factor=0.5,
            patience=10,
        )
        
        # ëª¨ë¸ ë¡œë“œ
        if model_path and os.path.exists(model_path):
            self.load_model(model_path)
        
        # ì˜ì‚¬ê²°ì • íˆìŠ¤í† ë¦¬
        self.decision_history = []
        self.performance_history = []
        
        # í†µê³„
        self.total_decisions = 0
        self.correct_decisions = 0
        self.total_profit = 0.0
    
    def _extract_features(self, decision_data: Dict) -> List[float]:
        """ë‹¨ì¼ Decision ë°ì´í„°ì—ì„œ 58ì°¨ì› íŠ¹ì„± ì¶”ì¶œ"""
        features = []
        
        # 1. ì „ëµ Action (16ê°œ)
        strategy_actions = [
            'bollinger_squeeze_action', 'zscore_mean_reversion_action', 'vpvr_action', 
            'ema_confluence_action', 'ichimoku_action', 'htf_trend_action', 
            'funding_rate_action', 'orderflow_cvd_action', 'support_resistance_action', 
            'vwap_pinball_action', 'multi_timeframe_action', 'session_action', 
            'vol_spike_action', 'vpvr_micro_action', 'oi_delta_action', 'liquidity_grab_action'
        ]
        
        for action_col in strategy_actions:
            action = decision_data.get(action_col, 'HOLD')
            if isinstance(action, str):
                if action.upper() == 'BUY':
                    action_value = 1.0
                elif action.upper() == 'SELL':
                    action_value = -1.0
                else:
                    action_value = 0.0
            else:
                action_value = float(action) if action else 0.0
            features.append(action_value)
        
        # 2. ì „ëµ Score (16ê°œ)
        strategy_scores = [
            'bollinger_squeeze_score', 'session_score', 'vpvr_score', 'oi_delta_score',
            'ema_confluence_score', 'multi_timeframe_score', 'vol_spike_score', 
            'vpvr_micro_score', 'htf_trend_score', 'liquidity_grab_score', 
            'ichimoku_score', 'funding_rate_score', 'support_resistance_score', 
            'zscore_mean_reversion_score', 'vwap_pinball_score', 'orderflow_cvd_score'
        ]
        
        for score_col in strategy_scores:
            features.append(float(decision_data.get(score_col, 0.0)))
        
        # 3. ì „ëµ Confidence (1ê°œ - vpvr_confidenceë§Œ ìˆìŒ)
        confidence = decision_data.get('vpvr_confidence', 0.0)
        if isinstance(confidence, str):
            confidence_value = 0.0
        else:
            confidence_value = float(confidence) if confidence else 0.0
        features.append(confidence_value)
        
        # 4. ì „ëµ Entry (4ê°œ)
        strategy_entries = ['vpvr_micro_entry', 'vwap_pinball_entry', 'session_entry', 'vpvr_entry']
        for entry_col in strategy_entries:
            features.append(float(decision_data.get(entry_col, 0.0)))
        
        # 5. ì „ëµ Stop (4ê°œ)
        strategy_stops = ['vpvr_stop', 'session_stop', 'vpvr_micro_stop', 'vwap_pinball_stop']
        for stop_col in strategy_stops:
            features.append(float(decision_data.get(stop_col, 0.0)))
        
        # 6. Indicator ì •ë³´ (10ê°œ)
        indicator_fields = [
            'indicator_prev_day_high', 'indicator_poc', 'indicator_hvn', 'indicator_vwap_std',
            'indicator_opening_range_high', 'indicator_lvn', 'indicator_opening_range_low',
            'indicator_vwap', 'indicator_prev_day_low', 'indicator_atr'
        ]
        
        for field in indicator_fields:
            features.append(float(decision_data.get(field, 0.0)))
        
        # 7. OHLC ë°ì´í„° (6ê°œ)
        features.extend([
            float(decision_data.get('open', 0.0)),
            float(decision_data.get('high', 0.0)),
            float(decision_data.get('low', 0.0)),
            float(decision_data.get('close', 0.0)),
            float(decision_data.get('volume', 0.0)),
            float(decision_data.get('quote_volume', 0.0))
        ])
        
        # 8. Timestamp (1ê°œ)
        timestamp = decision_data.get('timestamp', 0.0)
        if isinstance(timestamp, str):
            try:
                timestamp = pd.to_datetime(timestamp).timestamp()
            except:
                timestamp = 0.0
        else:
            timestamp = float(timestamp) if timestamp else 0.0
        
        features.append(timestamp)
        
        # ì°¨ì› ê²€ì¦
        assert len(features) == 58, f"Expected 58 features, got {len(features)}"
        
        return features
    
    def preprocess_decision_data(self, decision_data: Dict) -> torch.Tensor:
        """ë‹¨ì¼ Decision ë°ì´í„° ì „ì²˜ë¦¬ (í˜¸í™˜ì„± ìœ ì§€)"""
        features = self._extract_features(decision_data)
        return torch.FloatTensor(features).unsqueeze(0).to(self.device)
    
    def preprocess_sequence_data(self, decision_data: List[Dict], seq_len: int = 20) -> torch.Tensor:
        """ì‹œí€€ìŠ¤ í˜•íƒœë¡œ ë°ì´í„° ì „ì²˜ë¦¬"""
        sequences = []
        
        for i in range(len(decision_data) - seq_len + 1):
            sequence = []
            for j in range(seq_len):
                features = self._extract_features(decision_data[i + j])
                sequence.append(features)
            sequences.append(sequence)
        
        return torch.FloatTensor(sequences).to(self.device)
    
    def make_decision(self, decision_data: Dict) -> Dict:
        """ë‹¨ì¼ ë°ì´í„° ì˜ì‚¬ê²°ì • ìˆ˜í–‰ (í˜¸í™˜ì„± ìœ ì§€)"""
        self.model.eval()
        
        with torch.no_grad():
            # ë°ì´í„° ì „ì²˜ë¦¬
            input_tensor = self.preprocess_decision_data(decision_data)
            
            # ëª¨ë¸ ì¶”ë¡ 
            decisions, profit_pred, timeframe_features = self.model(input_tensor)
            
            # ì˜ì‚¬ê²°ì • ê²°ê³¼ ìƒì„± (ë‹¨ìˆœí™”)
            result = {
                'action': self._interpret_action(decisions['action']),
                'confidence': float(decisions['confidence'].item()),
                'profit': float(profit_pred.item()),
                'timestamp': datetime.now().isoformat(),
                'model_version': 'MultiTimeframeTransformer_v1.0'
            }
            
            # íˆìŠ¤í† ë¦¬ì— ì €ì¥
            self.decision_history.append({
                'input': decision_data,
                'output': result,
                'timestamp': datetime.now()
            })
            
            self.total_decisions += 1
            
            return result
    
    def make_sequence_decision(self, decision_sequence: List[Dict], seq_len: int = 20) -> Dict:
        """ì‹œí€€ìŠ¤ ê¸°ë°˜ ì˜ì‚¬ê²°ì • ìˆ˜í–‰ (Transformerì˜ ì§„ì •í•œ ì¥ì  í™œìš©)"""
        self.model.eval()
        
        with torch.no_grad():
            # ì‹œí€€ìŠ¤ ë°ì´í„° ì „ì²˜ë¦¬
            if len(decision_sequence) < seq_len:
                # ì‹œí€€ìŠ¤ê°€ ì§§ìœ¼ë©´ íŒ¨ë”©
                padded_sequence = decision_sequence + [decision_sequence[-1]] * (seq_len - len(decision_sequence))
                input_tensor = self.preprocess_sequence_data(padded_sequence, seq_len)
            else:
                # ë§ˆì§€ë§‰ seq_lenê°œë§Œ ì‚¬ìš©
                recent_sequence = decision_sequence[-seq_len:]
                input_tensor = self.preprocess_sequence_data(recent_sequence, seq_len)
            
            # ëª¨ë¸ ì¶”ë¡  (ì‹œí€€ìŠ¤ í˜•íƒœ)
            decisions, profit_pred, timeframe_features = self.model(input_tensor)
            
            # ì˜ì‚¬ê²°ì • ê²°ê³¼ ìƒì„± (ë‹¨ìˆœí™”)
            result = {
                'action': self._interpret_action(decisions['action']),
                'confidence': float(decisions['confidence'].item()),
                'profit': float(profit_pred.item()),
                'sequence_length': seq_len,
                'timestamp': datetime.now().isoformat(),
                'model_version': 'MultiTimeframeTransformer_v2.0_Sequence'
            }
            
            # íˆìŠ¤í† ë¦¬ì— ì €ì¥
            self.decision_history.append({
                'input': decision_sequence[-1] if decision_sequence else {},  # ë§ˆì§€ë§‰ ë°ì´í„°ë§Œ ì €ì¥
                'output': result,
                'timestamp': datetime.now()
            })
            
            self.total_decisions += 1
            
            return result
    
    def _interpret_action(self, action_logits: torch.Tensor) -> str:
        """ì•¡ì…˜ ë¡œì§“ì„ í•´ì„ (í™•ë¥  ë¶„í¬ í™•ì¸ í¬í•¨)"""
        # ì†Œí”„íŠ¸ë§¥ìŠ¤ ì ìš©í•˜ì—¬ í™•ë¥ ë¡œ ë³€í™˜
        probabilities = torch.softmax(action_logits, dim=-1)
        action_idx = torch.argmax(action_logits).item()
        actions = ['HOLD', 'BUY', 'SELL']
        
        # ë””ë²„ê¹…: ì•¡ì…˜ ë¶„í¬ ì¶œë ¥
        probs = probabilities.cpu().numpy()
        print(f"    ì•¡ì…˜ í™•ë¥ : HOLD={probs[0]:.3f}, BUY={probs[1]:.3f}, SELL={probs[2]:.3f}")
        
        return actions[action_idx]
    
    
    def train_on_batch(self, batch_data: List[Dict], batch_labels: List[Dict]) -> float:
        """ë‹¨ì¼ ë°ì´í„° ë°°ì¹˜ í•™ìŠµ (í˜¸í™˜ì„± ìœ ì§€)"""
        self.model.train()
        
        # ë°°ì¹˜ ì „ì²˜ë¦¬
        inputs = []
        targets = []
        
        for data, labels in zip(batch_data, batch_labels):
            input_tensor = self.preprocess_decision_data(data)
            inputs.append(input_tensor)
            
            # íƒ€ê²Ÿ ìƒì„± (ë‹¨ìˆœí™”)
            target = {
                'action': torch.tensor([labels.get('action', 0)], dtype=torch.long).to(self.device),
                'confidence': torch.tensor([labels.get('confidence', 0.5)], dtype=torch.float).to(self.device),
                'profit': torch.tensor([labels.get('profit', 0.0)], dtype=torch.float).to(self.device)
            }
            targets.append(target)
        
        # ë°°ì¹˜ ê²°í•©
        batch_input = torch.cat(inputs, dim=0)
        
        # ìˆœì „íŒŒ
        decisions, profit_pred, _ = self.model(batch_input)
        
        # ì†ì‹¤ ê³„ì‚° (ê°€ì¤‘ì¹˜ ì ìš©)
        total_loss = 0.0
        
        # ê°€ì¤‘ì¹˜ ì„¤ì •
        profit_loss_weight = 3.0  # ìˆ˜ìµë¥  ì˜ˆì¸¡ì— ê°€ì¥ ë†’ì€ ê°€ì¤‘ì¹˜
        action_loss_weight = 2.0  # ì•¡ì…˜ ë¶„ë¥˜ì— ë†’ì€ ê°€ì¤‘ì¹˜
        other_loss_weight = 1.0   # ê¸°íƒ€ íšŒê·€ì— ê¸°ë³¸ ê°€ì¤‘ì¹˜
        
        # ì•¡ì…˜ ë¶„ë¥˜ ì†ì‹¤
        action_targets = torch.cat([t['action'] for t in targets])
        action_loss = F.cross_entropy(decisions['action'], action_targets)
        total_loss += action_loss * action_loss_weight
        
        # íšŒê·€ ì†ì‹¤ë“¤ (ë‹¨ìˆœí™”)
        for key in ['confidence']:
            pred = decisions[key].squeeze()
            target = torch.cat([t[key] for t in targets])
            loss = F.mse_loss(pred, target)
            total_loss += loss * other_loss_weight
        
        # ìˆ˜ìµë¥  ì˜ˆì¸¡ ì†ì‹¤ (ê°€ì¥ ì¤‘ìš”)
        profit_targets = torch.cat([t['profit'] for t in targets])
        profit_loss = F.mse_loss(profit_pred.squeeze(), profit_targets)
        total_loss += profit_loss * profit_loss_weight
        
        # ì—­ì „íŒŒ
        self.optimizer.zero_grad()
        total_loss.backward()
        
        # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
        torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)
        
        self.optimizer.step()
        
        return float(total_loss.item())
    
    def train_on_sequence_batch(self, batch_sequences: List[List[Dict]], batch_labels: List[Dict], seq_len: int = 20) -> float:
        """ì‹œí€€ìŠ¤ ë°°ì¹˜ í•™ìŠµ (Transformerì˜ ì§„ì •í•œ ì¥ì  í™œìš©)"""
        self.model.train()
        
        # ë°°ì¹˜ ì „ì²˜ë¦¬
        inputs = []
        targets = []
        
        for sequence, labels in zip(batch_sequences, batch_labels):
            # âœ… ì‹œí€€ìŠ¤ë¥¼ ì§ì ‘ í…ì„œë¡œ ë³€í™˜ (preprocess_sequence_data ì‚¬ìš© ì•ˆ í•¨)
            if len(sequence) < seq_len:
                # íŒ¨ë”©
                padded_sequence = sequence + [sequence[-1]] * (seq_len - len(sequence))
            else:
                # ë§ˆì§€ë§‰ seq_lenê°œë§Œ ì‚¬ìš©
                padded_sequence = sequence[-seq_len:]
            
            # âœ… ì§ì ‘ íŠ¹ì„± ì¶”ì¶œ
            sequence_features = []
            for data_point in padded_sequence:
                features = self._extract_features(data_point)
                sequence_features.append(features)
            
            # [seq_len, feature_dim] â†’ [1, seq_len, feature_dim]
            input_tensor = torch.FloatTensor(sequence_features).unsqueeze(0).to(self.device)
            inputs.append(input_tensor)
            
            # íƒ€ê²Ÿ ìƒì„± (ë‹¨ìˆœí™”)
            target = {
                'action': torch.tensor([labels.get('action', 0)], dtype=torch.long).to(self.device),
                'confidence': torch.tensor([labels.get('confidence', 0.5)], dtype=torch.float).to(self.device),
                'profit': torch.tensor([labels.get('profit', 0.0)], dtype=torch.float).to(self.device)
            }
            targets.append(target)
        
        # ë°°ì¹˜ ê²°í•©
        batch_input = torch.cat(inputs, dim=0)
        
        # ìˆœì „íŒŒ
        decisions, profit_pred, _ = self.model(batch_input)
        
        # ì†ì‹¤ ê³„ì‚° (ê°€ì¤‘ì¹˜ ì ìš©)
        total_loss = 0.0
        
        # ê°€ì¤‘ì¹˜ ì„¤ì •
        profit_loss_weight = 3.0  # ìˆ˜ìµë¥  ì˜ˆì¸¡ì— ê°€ì¥ ë†’ì€ ê°€ì¤‘ì¹˜
        action_loss_weight = 2.0  # ì•¡ì…˜ ë¶„ë¥˜ì— ë†’ì€ ê°€ì¤‘ì¹˜
        other_loss_weight = 1.0   # ê¸°íƒ€ íšŒê·€ì— ê¸°ë³¸ ê°€ì¤‘ì¹˜
        
        # ì•¡ì…˜ ë¶„ë¥˜ ì†ì‹¤
        action_targets = torch.cat([t['action'] for t in targets])
        action_loss = F.cross_entropy(decisions['action'], action_targets)
        total_loss += action_loss * action_loss_weight
        
        # íšŒê·€ ì†ì‹¤ë“¤ (ë‹¨ìˆœí™”)
        for key in ['confidence']:
            pred = decisions[key].squeeze()
            target = torch.cat([t[key] for t in targets])
            loss = F.mse_loss(pred, target)
            total_loss += loss * other_loss_weight
        
        # ìˆ˜ìµë¥  ì˜ˆì¸¡ ì†ì‹¤ (ê°€ì¥ ì¤‘ìš”)
        profit_targets = torch.cat([t['profit'] for t in targets])
        profit_loss = F.mse_loss(profit_pred.squeeze(), profit_targets)
        total_loss += profit_loss * profit_loss_weight
        
        # ì—­ì „íŒŒ
        self.optimizer.zero_grad()
        total_loss.backward()
        
        # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
        torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)
        
        self.optimizer.step()
        
        return float(total_loss.item())
    
    def save_model(self, filepath: str) -> bool:
        """ëª¨ë¸ ì €ì¥"""
        try:
            os.makedirs(os.path.dirname(filepath) if os.path.dirname(filepath) else '.', exist_ok=True)
            
            save_dict = {
                'model_state_dict': self.model.state_dict(),
                'optimizer_state_dict': self.optimizer.state_dict(),
                'scheduler_state_dict': self.scheduler.state_dict(),
                'total_decisions': self.total_decisions,
                'correct_decisions': self.correct_decisions,
                'total_profit': self.total_profit,
                'decision_history': self.decision_history[-1000:],  # ìµœê·¼ 1000ê°œë§Œ ì €ì¥
                'model_config': {
                    'input_size': self.model.input_size,
                    'd_model': self.model.d_model,
                    'nhead': self.model.nhead,
                    'num_layers': self.model.num_layers
                }
            }
            
            torch.save(save_dict, filepath)
            print(f"Multi-Timeframe Transformer ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {filepath}")
            return True
            
        except Exception as e:
            print(f"ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def load_model(self, filepath: str) -> bool:
        """ëª¨ë¸ ë¡œë“œ"""
        if not os.path.exists(filepath):
            print(f"ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {filepath}")
            return False
        
        try:
            checkpoint = torch.load(filepath, map_location=self.device)
            
            # ëª¨ë¸ ìƒíƒœ ë¡œë“œ
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
            
            # í†µê³„ ë¡œë“œ
            self.total_decisions = checkpoint.get('total_decisions', 0)
            self.correct_decisions = checkpoint.get('correct_decisions', 0)
            self.total_profit = checkpoint.get('total_profit', 0.0)
            self.decision_history = checkpoint.get('decision_history', [])
            
            print(f"Multi-Timeframe Transformer ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {filepath}")
            print(f"   ì´ ì˜ì‚¬ê²°ì •: {self.total_decisions}")
            print(f"   ì •í™•ë„: {self.correct_decisions/max(self.total_decisions, 1):.3f}")
            print(f"   ì´ ìˆ˜ìµ: {self.total_profit:.3f}")
            
            return True
            
        except Exception as e:
            print(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def get_performance_stats(self) -> Dict:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        accuracy = self.correct_decisions / max(self.total_decisions, 1)
        avg_profit = self.total_profit / max(self.total_decisions, 1)
        
        return {
            'total_decisions': self.total_decisions,
            'correct_decisions': self.correct_decisions,
            'accuracy': accuracy,
            'total_profit': self.total_profit,
            'avg_profit_per_decision': avg_profit,
            'recent_decisions': len(self.decision_history)
        }

def create_sample_decision_data() -> Dict:
    """ìƒ˜í”Œ Decision ë°ì´í„° ìƒì„± (58ì°¨ì›)"""
    actions = ['HOLD', 'BUY', 'SELL']
    
    data = {}
    
    # 1. ì „ëµ Action (16ê°œ)
    strategy_actions = [
        'bollinger_squeeze_action', 'zscore_mean_reversion_action', 'vpvr_action', 
        'ema_confluence_action', 'ichimoku_action', 'htf_trend_action', 
        'funding_rate_action', 'orderflow_cvd_action', 'support_resistance_action', 
        'vwap_pinball_action', 'multi_timeframe_action', 'session_action', 
        'vol_spike_action', 'vpvr_micro_action', 'oi_delta_action', 'liquidity_grab_action'
    ]
    
    for action_col in strategy_actions:
        data[action_col] = random.choice(actions)
    
    # 2. ì „ëµ Score (16ê°œ)
    strategy_scores = [
        'bollinger_squeeze_score', 'session_score', 'vpvr_score', 'oi_delta_score',
        'ema_confluence_score', 'multi_timeframe_score', 'vol_spike_score', 
        'vpvr_micro_score', 'htf_trend_score', 'liquidity_grab_score', 
        'ichimoku_score', 'funding_rate_score', 'support_resistance_score', 
        'zscore_mean_reversion_score', 'vwap_pinball_score', 'orderflow_cvd_score'
    ]
    
    for score_col in strategy_scores:
        data[score_col] = random.uniform(0.0, 1.0)
    
    # 3. ì „ëµ Confidence (1ê°œ)
    data['vpvr_confidence'] = random.uniform(0.0, 1.0)
    
    # 4. ì „ëµ Entry (4ê°œ)
    strategy_entries = ['vpvr_micro_entry', 'vwap_pinball_entry', 'session_entry', 'vpvr_entry']
    for entry_col in strategy_entries:
        data[entry_col] = random.uniform(2000, 3000)
    
    # 5. ì „ëµ Stop (4ê°œ)
    strategy_stops = ['vpvr_stop', 'session_stop', 'vpvr_micro_stop', 'vwap_pinball_stop']
    for stop_col in strategy_stops:
        data[stop_col] = random.uniform(2000, 3000)
    
    # 6. Indicator ì •ë³´ (10ê°œ)
    indicator_fields = [
        'indicator_prev_day_high', 'indicator_poc', 'indicator_hvn', 'indicator_vwap_std',
        'indicator_opening_range_high', 'indicator_lvn', 'indicator_opening_range_low',
        'indicator_vwap', 'indicator_prev_day_low', 'indicator_atr'
    ]
    
    for field in indicator_fields:
        if 'atr' in field or 'std' in field:
            data[field] = random.uniform(1, 50)
        else:
            data[field] = random.uniform(2000, 3000)
    
    # 7. OHLC ë°ì´í„° (6ê°œ)
    base_price = random.uniform(2000, 3000)
    data['open'] = base_price
    data['high'] = base_price + random.uniform(0, 50)
    data['low'] = base_price - random.uniform(0, 50)
    data['close'] = base_price + random.uniform(-20, 20)
    data['volume'] = random.uniform(1000, 10000)
    data['quote_volume'] = random.uniform(1000000, 10000000)
    
    # 8. Timestamp (1ê°œ)
    data['timestamp'] = int(datetime.now().timestamp() * 1000)
    
    return data

class DecisionDataLoader:
    """Decision ë°ì´í„° ë¡œë”"""
    
    @staticmethod
    def load_decision_data(file_path: str = 'agent/decisions_data.parquet') -> Optional[List[Dict]]:
        """Decision ë°ì´í„° ë¡œë“œ"""
        if not os.path.exists(file_path):
            print(f"Decision ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            return None
        
        try:
            print(f"Decision ë°ì´í„° ë¡œë“œ ì¤‘: {file_path}")
            df = pd.read_parquet(file_path)
            print(f"Decision ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df):,}ê°œ ë ˆì½”ë“œ")
            
            # DataFrameì„ Dict ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            decision_data = []
            for idx, row in df.iterrows():
                decision_dict = {}
                for col, value in row.items():
                    if pd.notna(value):
                        decision_dict[col] = value
                    else:
                        # ê¸°ë³¸ê°’ ì„¤ì •
                        if 'score' in col or 'confidence' in col or 'value' in col:
                            decision_dict[col] = 0.0
                        elif 'count' in col or 'used' in col:
                            decision_dict[col] = 0
                        else:
                            decision_dict[col] = 0.0
                
                decision_data.append(decision_dict)
                
                if (idx + 1) % 10000 == 0:
                    print(f"  ë³€í™˜ ì§„í–‰: {idx + 1:,}/{len(df):,}")
            
            print(f"Decision ë°ì´í„° ë³€í™˜ ì™„ë£Œ: {len(decision_data):,}ê°œ")
            return decision_data
            
        except Exception as e:
            print(f"Decision ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    @staticmethod
    def create_training_labels(decision_data: List[Dict], lookforward_steps: int = 5):
        """ë¯¸ë˜ Nê°œ ìŠ¤í…ì˜ í‰ê·  ìˆ˜ìµë¥ ë¡œ ë¼ë²¨ ìƒì„± (ê¸°ì¡´ - Look-ahead Bias ìˆìŒ)"""
        labels = []
        
        for i, data in enumerate(decision_data):
            label = {
                'action': 0,
                'confidence': 0.5,
                'profit': 0.0
            }
            
            # ë¯¸ë˜ ì—¬ëŸ¬ ìŠ¤í…ì˜ í‰ê·  ìˆ˜ìµë¥  ê³„ì‚°
            if i < len(decision_data) - lookforward_steps:
                current_price = data.get('close', 0.0)
                future_prices = [
                    decision_data[i + j].get('close', 0.0) 
                    for j in range(1, lookforward_steps + 1)
                ]
                
                if current_price > 0 and all(p > 0 for p in future_prices):
                    # í‰ê·  ìˆ˜ìµë¥ 
                    avg_price_change = np.mean([
                        (p - current_price) / current_price 
                        for p in future_prices
                    ])
                    
                    # ë” ë³´ìˆ˜ì ì¸ ì„ê³„ê°’ (1% ì´ìƒ/ì´í•˜)
                    if avg_price_change > 0.01:
                        label['action'] = 1  # BUY
                        label['profit'] = avg_price_change
                        label['confidence'] = min(0.9, 0.5 + abs(avg_price_change) * 10)
                        
                    elif avg_price_change < -0.01:
                        label['action'] = 2  # SELL
                        label['profit'] = -avg_price_change
                        label['confidence'] = min(0.9, 0.5 + abs(avg_price_change) * 10)
            
            labels.append(label)
            
        return labels
    
    @staticmethod
    def create_realistic_training_labels(decision_data: List[Dict], lookback_steps: int = 20):
        """ë¯¸ë˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ê³ í’ˆì§ˆ ë¼ë²¨ ìƒì„± (ë°±í…ŒìŠ¤íŠ¸ìš©)"""
        labels = []
        
        for i in range(lookback_steps, len(decision_data) - 5):  # ë¯¸ë˜ 5ê°œ ìŠ¤í… í™•ë³´
            label = {
                'action': 0,
                'confidence': 0.5,
                'profit': 0.0
            }
            
            # ğŸ”¥ ë¯¸ë˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ê³ í’ˆì§ˆ ë¼ë²¨ ìƒì„±
            current_price = decision_data[i].get('close', 0.0)
            future_prices = [
                decision_data[i + j].get('close', 0.0) 
                for j in range(1, 6)  # ë‹¤ìŒ 5ê°œ ìŠ¤í…
            ]
            
            if current_price > 0 and all(p > 0 for p in future_prices):
                # ğŸ”¥ ë¯¸ë˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œ ì •í™•í•œ ë¼ë²¨ ìƒì„±
                # ë¯¸ë˜ 5ê°œ ìŠ¤í…ì˜ ìµœê³ ê°€, ìµœì €ê°€, í‰ê·  ìˆ˜ìµë¥  ê³„ì‚°
                future_returns = [(p - current_price) / current_price for p in future_prices]
                max_return = max(future_returns)
                min_return = min(future_returns)
                avg_return = np.mean(future_returns)
                
                # ê±°ë˜ëŸ‰ ë¶„ì„ (í˜„ì¬ + ë¯¸ë˜)
                current_volume = decision_data[i].get('volume')
                future_volumes = [decision_data[i + j].get('volume') for j in range(1, 6)]
                avg_volume = np.mean([current_volume] + future_volumes)
                
                # ğŸ”¥ ë¯¸ë˜ ìˆ˜ìµë¥  ê¸°ë°˜ ë¼ë²¨ ìƒì„± (í›¨ì”¬ ì •í™•í•¨)
                if max_return > 0.005:  # 0.5% ì´ìƒ ìƒìŠ¹ ê°€ëŠ¥
                    label['action'] = 1  # BUY
                    label['profit'] = max_return  # ì‹¤ì œ ë¯¸ë˜ ìˆ˜ìµë¥ 
                    label['confidence'] = min(0.95, 0.6 + max_return * 20)  # ë†’ì€ ì‹ ë¢°ë„
                    
                elif min_return < -0.005:  # 0.5% ì´ìƒ í•˜ë½ ê°€ëŠ¥
                    label['action'] = 2  # SELL
                    label['profit'] = -min_return  # ì‹¤ì œ ë¯¸ë˜ ìˆ˜ìµë¥  (ì ˆëŒ“ê°’)
                    label['confidence'] = min(0.95, 0.6 + abs(min_return) * 20)  # ë†’ì€ ì‹ ë¢°ë„
                    
                else:
                    # Hold - í° ì›€ì§ì„ ì—†ìŒ
                    label['action'] = 0
                    label['profit'] = 0.0
                    label['confidence'] = 0.3
            
            labels.append(label)
        
        # ì•¡ì…˜ ë¶„í¬ í†µê³„ ì¶œë ¥
        action_counts = {'HOLD': 0, 'BUY': 0, 'SELL': 0}
        for label in labels:
            action_counts[['HOLD', 'BUY', 'SELL'][label['action']]] += 1
        
        total_labels = len(labels)
        print(f"  ğŸ“Š ë¼ë²¨ ì•¡ì…˜ ë¶„í¬:")
        print(f"    HOLD: {action_counts['HOLD']:,}ê°œ ({action_counts['HOLD']/total_labels*100:.1f}%)")
        print(f"    BUY:  {action_counts['BUY']:,}ê°œ ({action_counts['BUY']/total_labels*100:.1f}%)")
        print(f"    SELL: {action_counts['SELL']:,}ê°œ ({action_counts['SELL']/total_labels*100:.1f}%)")
        
        return labels

class MultiTimeframeTrainer:
    """Multi-Timeframe Transformer í›ˆë ¨ í´ë˜ìŠ¤"""
    
    def __init__(self, engine: MultiTimeframeDecisionEngine):
        self.engine = engine
        self.training_history = []
    
    def train_on_sequence_data(self, 
                                decision_data: List[Dict], 
                                seq_len: int = 20,  # labels íŒŒë¼ë¯¸í„° ì œê±°
                                batch_size: int = 32,
                                epochs: int = 10,
                                validation_split: float = 0.2) -> Dict:
        """ì‹œí€€ìŠ¤ ë°ì´í„°ë¡œ í›ˆë ¨ (Transformerì˜ ì§„ì •í•œ ì¥ì  í™œìš©)"""
        print(f"Multi-Timeframe Transformer ì‹œí€€ìŠ¤ í›ˆë ¨ ì‹œì‘")
        print(f"  ë°ì´í„° í¬ê¸°: {len(decision_data):,}ê°œ")
        print(f"  ì‹œí€€ìŠ¤ ê¸¸ì´: {seq_len}")
        print(f"  ë°°ì¹˜ í¬ê¸°: {batch_size}")
        print(f"  ì—í¬í¬: {epochs}")
        print(f"  ê²€ì¦ ë¹„ìœ¨: {validation_split:.1%}")
        
        # ë°ì´í„° ë¶„í• 
        split_idx = int(len(decision_data) * (1 - validation_split))
        train_data_raw = decision_data[:split_idx]
        val_data_raw = decision_data[split_idx:]
        
        # ì •ê·œí™”
        normalizer = DataNormalizer()
        train_data_raw = normalizer.fit_transform(train_data_raw)
        val_data_raw = normalizer.transform(val_data_raw)
        
        # ë¼ë²¨ ìƒì„±
        train_realistic_labels = DecisionDataLoader.create_realistic_training_labels(
            train_data_raw, lookback_steps=seq_len
        )
        val_realistic_labels = DecisionDataLoader.create_realistic_training_labels(
            val_data_raw, lookback_steps=seq_len
        )
        
        print(f"  í›ˆë ¨ ë¼ë²¨: {len(train_realistic_labels):,}ê°œ")
        print(f"  ê²€ì¦ ë¼ë²¨: {len(val_realistic_labels):,}ê°œ")
        
        # ì‹œí€€ìŠ¤ ìƒì„± (ìˆ˜ì •ë¨)
        train_sequences = []
        train_sequence_labels = []
        
        for i in range(len(train_realistic_labels)):
            sequence = train_data_raw[i:i + seq_len]
            label = train_realistic_labels[i]
            
            train_sequences.append(sequence)
            train_sequence_labels.append(label)
        
        val_sequences = []
        val_sequence_labels = []
        
        for i in range(len(val_realistic_labels)):
            sequence = val_data_raw[i:i + seq_len]
            label = val_realistic_labels[i]
            
            val_sequences.append(sequence)
            val_sequence_labels.append(label)
        
        print(f"  í›ˆë ¨ ì‹œí€€ìŠ¤: {len(train_sequences):,}ê°œ")
        print(f"  ê²€ì¦ ì‹œí€€ìŠ¤: {len(val_sequences):,}ê°œ")
        
        # í›ˆë ¨ ë£¨í”„
        best_val_loss = float('inf')
        patience = 20
        patience_counter = 0
        
        for epoch in range(epochs):
            # í›ˆë ¨
            train_loss = self._train_sequence_epoch(train_sequences, train_sequence_labels, seq_len, batch_size)
            
            # ê²€ì¦
            val_loss = self._validate_sequence_epoch(val_sequences, val_sequence_labels, seq_len, batch_size)
            
            # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
            self.engine.scheduler.step(val_loss)
            
            # íˆìŠ¤í† ë¦¬ ì €ì¥
            epoch_stats = {
                'epoch': epoch + 1,
                'train_loss': train_loss,
                'val_loss': val_loss,
                'lr': self.engine.optimizer.param_groups[0]['lr']
            }
            self.training_history.append(epoch_stats)
            
            # ì§„í–‰ ìƒí™© ì¶œë ¥
            print(f"Epoch {epoch+1:3d}/{epochs} | "
                  f"Train Loss: {train_loss:.4f} | "
                  f"Val Loss: {val_loss:.4f} | "
                  f"LR: {self.engine.optimizer.param_groups[0]['lr']:.2e}")
            
            # ì¡°ê¸° ì¢…ë£Œ
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                patience_counter = 0
                # ìµœê³  ëª¨ë¸ ì €ì¥
                self.engine.save_model('agent/best_multitimeframe_sequence_model.pth')
            else:
                patience_counter += 1
                if patience_counter >= patience:
                    print(f"ì¡°ê¸° ì¢…ë£Œ: {patience} ì—í¬í¬ ë™ì•ˆ ê°œì„  ì—†ìŒ")
                    break
        
        print(f"ì‹œí€€ìŠ¤ í›ˆë ¨ ì™„ë£Œ! ìµœê³  ê²€ì¦ ì†ì‹¤: {best_val_loss:.4f}")
        
        return {
            'best_val_loss': best_val_loss,
            'total_epochs': len(self.training_history),
            'training_history': self.training_history,
            'sequence_length': seq_len
        }
    
    def _train_sequence_epoch(self, sequences: List[List[Dict]], labels: List[Dict], seq_len: int, batch_size: int) -> float:
        """ì‹œí€€ìŠ¤ ì—í¬í¬ í›ˆë ¨"""
        self.engine.model.train()
        
        total_loss = 0.0
        num_batches = 0
        
        # ë°ì´í„° ì…”í”Œ
        indices = list(range(len(sequences)))
        random.shuffle(indices)
        total_batches = (len(sequences) + batch_size - 1) // batch_size
        
        for i in range(0, len(sequences), batch_size):
            batch_indices = indices[i:i + batch_size]
            batch_sequences = [sequences[idx] for idx in batch_indices]
            batch_labels = [labels[idx] for idx in batch_indices]
            
            if i % 100 == 0:
                print(f"    ë°°ì¹˜ {num_batches}/{total_batches} ì²˜ë¦¬ ì¤‘... ({num_batches/total_batches*100:.1f}%)")
            
            loss = self.engine.train_on_sequence_batch(batch_sequences, batch_labels, seq_len)
            total_loss += loss
            num_batches += 1
        
        return total_loss / num_batches if num_batches > 0 else 0.0
    
    def _validate_sequence_epoch(self, sequences: List[List[Dict]], labels: List[Dict], seq_len: int, batch_size: int) -> float:
        """ì‹œí€€ìŠ¤ ì—í¬í¬ ê²€ì¦"""
        self.engine.model.eval()
        
        total_loss = 0.0
        num_batches = 0
        
        with torch.no_grad():
            for i in range(0, len(sequences), batch_size):
                batch_sequences = sequences[i:i + batch_size]
                batch_labels = labels[i:i + batch_size]
                
                # ê²€ì¦ìš© ì†ì‹¤ ê³„ì‚°
                loss = self._compute_sequence_validation_loss(batch_sequences, batch_labels, seq_len)
                total_loss += loss
                num_batches += 1
        
        return total_loss / num_batches if num_batches > 0 else 0.0
    
    def _compute_sequence_validation_loss(self, batch_sequences: List[List[Dict]], batch_labels: List[Dict], seq_len: int) -> float:
        """ì‹œí€€ìŠ¤ ê²€ì¦ ì†ì‹¤ ê³„ì‚°"""
        # ë°°ì¹˜ ì „ì²˜ë¦¬
        inputs = []
        targets = []
        
        for sequence, labels in zip(batch_sequences, batch_labels):
            # ì‹œí€€ìŠ¤ ê¸¸ì´ ì¡°ì •
            if len(sequence) < seq_len:
                padded_sequence = sequence + [sequence[-1]] * (seq_len - len(sequence))
            else:
                padded_sequence = sequence[-seq_len:]
            
            # ì§ì ‘ íŠ¹ì„± ì¶”ì¶œ
            sequence_features = []
            for data_point in padded_sequence:
                features = self.engine._extract_features(data_point)
                sequence_features.append(features)
            
            # [seq_len, feature_dim] â†’ [1, seq_len, feature_dim]
            input_tensor = torch.FloatTensor(sequence_features).unsqueeze(0).to(self.engine.device)
            inputs.append(input_tensor)
            
            # íƒ€ê²Ÿ ìƒì„±
            target = {
                'action': torch.tensor([labels.get('action', 0)], dtype=torch.long).to(self.engine.device),
                'confidence': torch.tensor([labels.get('confidence', 0.5)], dtype=torch.float).to(self.engine.device),
                'position_size': torch.tensor([labels.get('position_size', 0.5)], dtype=torch.float).to(self.engine.device),
                'leverage': torch.tensor([labels.get('leverage', 0.5)], dtype=torch.float).to(self.engine.device),
                'holding_time': torch.tensor([labels.get('holding_time', 0.5)], dtype=torch.float).to(self.engine.device),
                'profit': torch.tensor([labels.get('profit', 0.0)], dtype=torch.float).to(self.engine.device)
            }
            targets.append(target)
        
        # ë°°ì¹˜ ê²°í•©
        batch_input = torch.cat(inputs, dim=0)
        
        # ìˆœì „íŒŒ
        decisions, profit_pred, _ = self.engine.model(batch_input)
        
        # ì†ì‹¤ ê³„ì‚°
        total_loss = 0.0
        
        # ì•¡ì…˜ ë¶„ë¥˜ ì†ì‹¤
        action_targets = torch.cat([t['action'] for t in targets])
        action_loss = F.cross_entropy(decisions['action'], action_targets)
        total_loss += action_loss
        
        # íšŒê·€ ì†ì‹¤ë“¤ (ë‹¨ìˆœí™”)
        for key in ['confidence']:
            pred = decisions[key].squeeze()
            target = torch.cat([t[key] for t in targets])
            loss = F.mse_loss(pred, target)
            total_loss += loss
        
        # ìˆ˜ìµë¥  ì˜ˆì¸¡ ì†ì‹¤
        profit_targets = torch.cat([t['profit'] for t in targets])
        profit_loss = F.mse_loss(profit_pred.squeeze(), profit_targets)
        total_loss += profit_loss
        
        return float(total_loss.item())
    
    def train_on_decision_data(self, 
                              decision_data: List[Dict], 
                              labels: List[Dict],
                              batch_size: int = 32,
                              epochs: int = 10,
                              validation_split: float = 0.2) -> Dict:
        """Decision ë°ì´í„°ë¡œ í›ˆë ¨"""
        print(f"Multi-Timeframe Transformer í›ˆë ¨ ì‹œì‘")
        print(f"  ë°ì´í„° í¬ê¸°: {len(decision_data):,}ê°œ")
        print(f"  ë°°ì¹˜ í¬ê¸°: {batch_size}")
        print(f"  ì—í¬í¬: {epochs}")
        print(f"  ê²€ì¦ ë¹„ìœ¨: {validation_split:.1%}")
        
        # ğŸ”¥ ë°ì´í„° ë¶„í•  ë¨¼ì € (ì •ê·œí™” ì „ì—!)
        split_idx = int(len(decision_data) * (1 - validation_split))
        train_data = decision_data[:split_idx]
        train_labels = labels[:split_idx]
        val_data = decision_data[split_idx:]
        val_labels = labels[split_idx:]
        
        print(f"  í›ˆë ¨ ë°ì´í„°: {len(train_data):,}ê°œ")
        print(f"  ê²€ì¦ ë°ì´í„°: {len(val_data):,}ê°œ")
        
        # ğŸ”¥ í›ˆë ¨ì…‹ìœ¼ë¡œë§Œ ì •ê·œí™” fit
        print("  í›ˆë ¨ì…‹ìœ¼ë¡œ ì •ê·œí™” fit ì¤‘...")
        normalizer = DataNormalizer()
        train_data = normalizer.fit_transform(train_data)
        
        # ğŸ”¥ ê²€ì¦ì…‹ì€ transformë§Œ (fit ì—†ì´!)
        print("  ê²€ì¦ì…‹ì— ì •ê·œí™” transform ì ìš© ì¤‘...")
        val_data = normalizer.transform(val_data)
        
        # í›ˆë ¨ ë£¨í”„
        best_val_loss = float('inf')
        patience = 20  # ë” ê´€ëŒ€í•œ ì¡°ê¸° ì¢…ë£Œ
        patience_counter = 0
        
        for epoch in range(epochs):
            # í›ˆë ¨
            train_loss = self._train_epoch(train_data, train_labels, batch_size)
            
            # ê²€ì¦
            val_loss = self._validate_epoch(val_data, val_labels, batch_size)
            
            # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸
            self.engine.scheduler.step(val_loss)
            
            # íˆìŠ¤í† ë¦¬ ì €ì¥
            epoch_stats = {
                'epoch': epoch + 1,
                'train_loss': train_loss,
                'val_loss': val_loss,
                'lr': self.engine.optimizer.param_groups[0]['lr']
            }
            self.training_history.append(epoch_stats)
            
            # ì§„í–‰ ìƒí™© ì¶œë ¥
            print(f"Epoch {epoch+1:3d}/{epochs} | "
                  f"Train Loss: {train_loss:.4f} | "
                  f"Val Loss: {val_loss:.4f} | "
                  f"LR: {self.engine.optimizer.param_groups[0]['lr']:.2e}")
            
            # ì¡°ê¸° ì¢…ë£Œ
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                patience_counter = 0
                # ìµœê³  ëª¨ë¸ ì €ì¥
                self.engine.save_model('agent/best_multitimeframe_model.pth')
            else:
                patience_counter += 1
                if patience_counter >= patience:
                    print(f"ì¡°ê¸° ì¢…ë£Œ: {patience} ì—í¬í¬ ë™ì•ˆ ê°œì„  ì—†ìŒ")
                    break
        
        print(f"í›ˆë ¨ ì™„ë£Œ! ìµœê³  ê²€ì¦ ì†ì‹¤: {best_val_loss:.4f}")
        
        return {
            'best_val_loss': best_val_loss,
            'total_epochs': len(self.training_history),
            'training_history': self.training_history
        }
    
    def _train_epoch(self, data: List[Dict], labels: List[Dict], batch_size: int) -> float:
        """í•œ ì—í¬í¬ í›ˆë ¨"""
        self.engine.model.train()
        
        total_loss = 0.0
        num_batches = 0
        
        # ë°ì´í„° ì…”í”Œ
        indices = list(range(len(data)))
        random.shuffle(indices)
        
        for i in range(0, len(data), batch_size):
            batch_indices = indices[i:i + batch_size]
            batch_data = [data[idx] for idx in batch_indices]
            batch_labels = [labels[idx] for idx in batch_indices]
            
            loss = self.engine.train_on_batch(batch_data, batch_labels)
            total_loss += loss
            num_batches += 1
        
        return total_loss / num_batches if num_batches > 0 else 0.0
    
    def _validate_epoch(self, data: List[Dict], labels: List[Dict], batch_size: int) -> float:
        """í•œ ì—í¬í¬ ê²€ì¦"""
        self.engine.model.eval()
        
        total_loss = 0.0
        num_batches = 0
        
        with torch.no_grad():
            for i in range(0, len(data), batch_size):
                batch_data = data[i:i + batch_size]
                batch_labels = labels[i:i + batch_size]
                
                # ê²€ì¦ìš© ì†ì‹¤ ê³„ì‚° (í›ˆë ¨í•˜ì§€ ì•ŠìŒ)
                loss = self._compute_validation_loss(batch_data, batch_labels)
                total_loss += loss
                num_batches += 1
        
        return total_loss / num_batches if num_batches > 0 else 0.0
    
    def _compute_validation_loss(self, batch_data: List[Dict], batch_labels: List[Dict]) -> float:
        """ê²€ì¦ ì†ì‹¤ ê³„ì‚°"""
        # ë°°ì¹˜ ì „ì²˜ë¦¬
        inputs = []
        targets = []
        
        for data, labels in zip(batch_data, batch_labels):
            input_tensor = self.engine.preprocess_decision_data(data)
            inputs.append(input_tensor)
            
            target = {
                'action': torch.tensor([labels.get('action', 0)], dtype=torch.long).to(self.engine.device),
                'confidence': torch.tensor([labels.get('confidence', 0.5)], dtype=torch.float).to(self.engine.device),
                'position_size': torch.tensor([labels.get('position_size', 0.5)], dtype=torch.float).to(self.engine.device),
                'leverage': torch.tensor([labels.get('leverage', 0.5)], dtype=torch.float).to(self.engine.device),
                'holding_time': torch.tensor([labels.get('holding_time', 0.5)], dtype=torch.float).to(self.engine.device),
                'profit': torch.tensor([labels.get('profit', 0.0)], dtype=torch.float).to(self.engine.device)
            }
            targets.append(target)
        
        # ë°°ì¹˜ ê²°í•©
        batch_input = torch.cat(inputs, dim=0)
        
        # ìˆœì „íŒŒ
        decisions, profit_pred, _ = self.engine.model(batch_input)
        
        # ì†ì‹¤ ê³„ì‚°
        total_loss = 0.0
        
        # ì•¡ì…˜ ë¶„ë¥˜ ì†ì‹¤
        action_targets = torch.cat([t['action'] for t in targets])
        action_loss = F.cross_entropy(decisions['action'], action_targets)
        total_loss += action_loss
        
        # íšŒê·€ ì†ì‹¤ë“¤ (ë‹¨ìˆœí™”)
        for key in ['confidence']:
            pred = decisions[key].squeeze()
            target = torch.cat([t[key] for t in targets])
            loss = F.mse_loss(pred, target)
            total_loss += loss
        
        # ìˆ˜ìµë¥  ì˜ˆì¸¡ ì†ì‹¤
        profit_targets = torch.cat([t['profit'] for t in targets])
        profit_loss = F.mse_loss(profit_pred.squeeze(), profit_targets)
        total_loss += profit_loss
        
        return float(total_loss.item())

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("Multi-Timeframe Transformer ë”¥ëŸ¬ë‹ ëª¨ë¸")
    print("=" * 60)
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    engine = MultiTimeframeDecisionEngine(
        input_size=58,
        d_model=256,
        nhead=8,
        num_layers=6
    )
    
    # 1. Decision ë°ì´í„° ë¡œë“œ (í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì œí•œ)
    print("\n1ï¸âƒ£ Decision ë°ì´í„° ë¡œë“œ...")
    decision_data = DecisionDataLoader.load_decision_data('agent/decisions_data.parquet')
    
    # # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë°ì´í„° ì œí•œ (ì²˜ìŒ 10,000ê°œë§Œ ì‚¬ìš©)
    # if len(decision_data) > 100000:
    #     decision_data = decision_data[:100000]
    #     print(f"   ğŸ§ª í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë°ì´í„°ë¥¼ 10,000ê°œë¡œ ì œí•œí–ˆìŠµë‹ˆë‹¤.")
    
    # 2. ë°ì´í„° ì •ê·œí™”ëŠ” í›ˆë ¨ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ìˆ˜í–‰ (Look-ahead Bias ë°©ì§€)
    print("\n2ï¸âƒ£ ë°ì´í„° ì •ê·œí™”ëŠ” í›ˆë ¨ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ìˆ˜í–‰ë©ë‹ˆë‹¤.")
    print("   ğŸ”¥ Look-ahead Bias ë°©ì§€ë¥¼ ìœ„í•´ í›ˆë ¨/ê²€ì¦ ë¶„í•  í›„ ì •ê·œí™” ì ìš©")
    # ì •ê·œí™”ëŠ” train_on_sequence_data í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ìˆ˜í–‰ë¨
    
    # 3. Decision ë°ì´í„°ì—ì„œ ê°€ê²© ì •ë³´ ì¶”ì¶œ
    print("\n3ï¸âƒ£ Decision ë°ì´í„°ì—ì„œ ê°€ê²© ì •ë³´ ì¶”ì¶œ...")
    price_data = []
    for data in decision_data:
        price_row = {
            'open': data.get('open'),
            'high': data.get('high'),
            'low': data.get('low'),
            'close': data.get('close'),
            'volume': data.get('volume'),
            'quote_volume': data.get('quote_volume')
        }
        price_data.append(price_row)
    
    price_df = pd.DataFrame(price_data)
    print(f"ê°€ê²© ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ: {len(price_df):,}ê°œ")

    # 4. í›ˆë ¨ ì‹¤í–‰ (ì‹œí€€ìŠ¤ ê¸°ë°˜) - ë¼ë²¨ ìƒì„±ì€ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì²˜ë¦¬
    print("\n4ï¸âƒ£ Multi-Timeframe Transformer ì‹œí€€ìŠ¤ í›ˆë ¨ ì‹œì‘...")
    print("   ğŸ”¥ Look-ahead Bias ë°©ì§€ë¥¼ ìœ„í•´ í˜„ì‹¤ì ì¸ ë¼ë²¨ ìƒì„± ë°©ë²• ì‚¬ìš©")
    print("   ğŸ”¥ ë¼ë²¨ ìƒì„±ì€ í›ˆë ¨ í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ë°ì´í„° ë¶„í•  í›„ ìˆ˜í–‰")
    
    print(f"ìµœì¢… ë°ì´í„° ê¸¸ì´: {len(decision_data):,}ê°œ")
    
    trainer = MultiTimeframeTrainer(engine)
    training_results = trainer.train_on_sequence_data(
        decision_data=decision_data,
        seq_len=30,  # 20 ìŠ¤í… ì‹œí€€ìŠ¤
        batch_size=64,  # ì‹œí€€ìŠ¤ ë°ì´í„°ëŠ” ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ í¬ë¯€ë¡œ ë°°ì¹˜ í¬ê¸° ì¡°ì •
        epochs=100,
        validation_split=0.2
    )
    
    # 6. í›ˆë ¨ ê²°ê³¼ ì¶œë ¥
    print(f"\n6ï¸âƒ£ í›ˆë ¨ ê²°ê³¼:")
    print(f"  ìµœê³  ê²€ì¦ ì†ì‹¤: {training_results['best_val_loss']:.4f}")
    print(f"  ì´ ì—í¬í¬: {training_results['total_epochs']}")
    
    # 7. í…ŒìŠ¤íŠ¸ (ì‹œí€€ìŠ¤ ê¸°ë°˜)
    print(f"\n7ï¸âƒ£ í›ˆë ¨ëœ ì‹œí€€ìŠ¤ ëª¨ë¸ í…ŒìŠ¤íŠ¸...")
    
    # ë‹¨ì¼ ë°ì´í„° í…ŒìŠ¤íŠ¸ (í˜¸í™˜ì„±)
    test_data = decision_data[0]
    decision = engine.make_decision(test_data)
    print("ë‹¨ì¼ ë°ì´í„° í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    print(f"  ì•¡ì…˜: {decision['action']}")
    print(f"  ì‹ ë¢°ë„: {decision['confidence']:.3f}")
    print(f"  ìˆ˜ìµë¥  ì˜ˆì¸¡: {decision['profit']:.3f}")
    
    # ì‹œí€€ìŠ¤ ë°ì´í„° í…ŒìŠ¤íŠ¸ (ìƒˆë¡œìš´ ê¸°ëŠ¥)
    if len(decision_data) >= 20:
        print("\nì‹œí€€ìŠ¤ ë°ì´í„° í…ŒìŠ¤íŠ¸ (10ê°œ ìƒ˜í”Œ):")
        
        # ì—¬ëŸ¬ ìƒ˜í”Œ í…ŒìŠ¤íŠ¸í•˜ì—¬ ì•¡ì…˜ ë¶„í¬ í™•ì¸
        test_action_counts = {'HOLD': 0, 'BUY': 0, 'SELL': 0}
        
        for i in range(min(10, len(decision_data) - 20)):
            test_sequence = decision_data[i:i+20]  # 20ê°œì”© ìŠ¬ë¼ì´ë”© ìœˆë„ìš°
            sequence_decision = engine.make_sequence_decision(test_sequence, seq_len=20)
            
            action = sequence_decision['action']
            test_action_counts[action] += 1
            
            if i < 3:  # ì²˜ìŒ 3ê°œë§Œ ìƒì„¸ ì¶œë ¥
                print(f"  ìƒ˜í”Œ {i+1}:")
                print(f"    ì•¡ì…˜: {action}")
                print(f"    ì‹ ë¢°ë„: {sequence_decision['confidence']:.3f}")
                print(f"    ìˆ˜ìµë¥  ì˜ˆì¸¡: {sequence_decision['profit']:.3f}")
        
        # ì•¡ì…˜ ë¶„í¬ í†µê³„
        total_tests = sum(test_action_counts.values())
        print(f"\n  ğŸ“Š í…ŒìŠ¤íŠ¸ ì•¡ì…˜ ë¶„í¬ (ì´ {total_tests}ê°œ ìƒ˜í”Œ):")
        print(f"    HOLD: {test_action_counts['HOLD']}ê°œ ({test_action_counts['HOLD']/total_tests*100:.1f}%)")
        print(f"    BUY:  {test_action_counts['BUY']}ê°œ ({test_action_counts['BUY']/total_tests*100:.1f}%)")
        print(f"    SELL: {test_action_counts['SELL']}ê°œ ({test_action_counts['SELL']/total_tests*100:.1f}%)")
    
    # 8. ìµœì¢… ëª¨ë¸ ì €ì¥
    engine.save_model('agent/multitimeframe_transformer_trained.pth')
    print(f"\nâœ… í›ˆë ¨ëœ ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: agent/multitimeframe_transformer_trained.pth")

if __name__ == "__main__":
    main()
